<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      A Model A Day &middot; By Akhil Rao
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          A Model A Day
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/archive/">Archive</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/akhilrao/archive/v0.0.1.zip">Download</a>
      <a class="sidebar-nav-item" href="https://github.com/akhilrao">GitHub project</a>
      <span class="sidebar-nav-item">Currently v0.0.1</span>
    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/macro%20theory/2015/10/18/variable-capacity-utilization/">
        A representative agent's variable capacity utilization problem
      </a>
    </h1>

    <span class="post-date">18 Oct 2015</span>

    <p>Suppose a planner is solving a representative agent&#39;s problem. The agent can use capital at a varying rate \(\mu \in [0,1] \) and the depreciation rate \( \delta \) is affected by capital utilization, specifically \( \delta( \mu ) = \delta \mu^{\alpha} \) with \( 1 \lt \alpha \lt \infty \). The planner solves</p>

<p>$$ \begin{align}
\max_{\{c_t\},\{x_t\},\{k_{t+1}\},\{\mu_t\}} ~~ &amp; \sum_{t=0}^{\infty} \beta^t u(c_t) \cr
\text{s.t.}~~ &amp; c_t + x_t \le f( \mu_t k_t ) \cr
&amp; k_{t+1} \le (1-\delta(\mu_t))k_t + x_t \cr
&amp; c \ge 0,~ x_t \ge 0,~ k_{t+1} \ge 0,~ \mu_t \in [0,1] ~~ \forall t \cr
\end{align} $$</p>

<p>where \( \beta \in (0,1) \), \(k_0 \gt 0 \), and \( \delta \in (0,1) \). The utility function \(u\) and production function \(f\) are strictly concave, strictly increasing, and twice continuously differentiable, with \(f(0) = 0 \).</p>

<p>The planner&#39;s lagrangian is</p>

<p>$$\begin{align}
\mathcal{L} = &amp; u(c_t) + \lambda_{1,t}[f(\mu_t k_t) - c_t - x_t] + \lambda_{2,t}[(1-\delta\mu^{\alpha})k_t + x_t - k_{t+1}] \cr &amp; + \gamma_{1,t} c_t + \gamma_{2,t} x_t + \gamma_{3,t} k_{t+1} + \gamma_{4,t} \mu_t + \gamma_{5,t}(1- \mu_t) \cr 
\end{align}$$</p>

<h3 id="saddle-point-conditions">Saddle Point Conditions</h3>

<p>We can rule out 4 corners: \(c_t =0 ~~\forall t\),\(k_{t+1} =0 ~~\forall t\),\(x_t =0 ~~\forall t\),\(\mu_t =0 ~~\forall t\). The contradictions come from \(u\) being strictly concave and strictly increasing, so \(c_t\) can&#39;t be 0. Assuming the choice variables are all greater than 0, we get the following saddle point conditions:</p>

<p>$$ \begin{align}
u&#39;(c_t ) = &amp; \lambda_{1,t} \cr
\lambda_{1,t} = &amp; \lambda_{2,t} \cr
\lambda_{1,t} = &amp; \beta \lambda_{1,t+1} (\mu_{t+1} f^{k} (\mu_{t+1} k_{t+1}) + (1- \delta \mu^{\alpha})) \cr
\gamma_{5,t} = &amp; \lambda_{1,t} k_t (f^{\mu} (\mu_t k_t) - \delta \alpha \mu^{\alpha-1}) \cr
\end{align}$$</p>

<p>$$\begin{align}
\lambda_{1,t}(f(\mu_t k_t) - c_t - x_t) &amp; = 0 \cr
\lambda_{2,t}((1- \delta \mu^{\alpha})k_t + c_t - k_{t+1}) &amp; = 0 \cr
\gamma_{5,t} (1- \mu_t) &amp; = 0 \cr
\end{align} $$</p>

<p>where \( f^{\mu} (\mu k) \) and \( f^k (\mu k) \) are the partial derivatives of \( f \) with respect to the superscripted arguments. </p>

<p>Since this is an infinite-horizon problem, we need something to rule out an unbounded solution for the asset. One way to do this is with a <a href="http://www.rieb.kobe-u.ac.jp/academic/ra/dp/English/dp180.pdf">transversality condition (TVC)</a>. I think we need a TVC for each asset variable in the economy to rule out bubbles in those assets.</p>

<p>We can derive the TVC for capital as follows: 
Suppose \(T\) is the final period. Then \( \gamma_{3,T}k_{T+1} = 0\). In the final period, all \(T+1\) multipliers must be 0. So \( \gamma_{3,T} = \lambda_{1,T} \). Discounting back to \(t=0\), \( \beta^T \lambda_{1,T} K_{T+1} = 0 \), and in the limit, \( \lim_{T \to \infty} \beta^T \lambda_{1,T} K_{T+1} = 0 \). </p>

<p>Full capacity utilization may be optimal.</p>

<h3 id="the-steady-state">The Steady State</h3>

<p>The steady state is when the choice variables of the model are stationary. Here, \( c_t = c^*, k_t = k_{t+1} = k^* , x_t = x^*, \mu_t = \mu^* ~~ \forall t\).</p>

<p>In the steady state, the saddle point conditions become</p>

<p>$$ \begin{align}
&amp; \beta ( \mu^* f^k (\mu^* k^*) + (1-\delta \mu^{* \alpha})) = 1 \cr
&amp; \gamma_{5}^* = \lambda_{1}^* k^* (f^{\mu} (\mu^* k^*) - \delta \alpha \mu ^{* \alpha - 1}) \cr
&amp; \gamma_{5}^* (1- \mu^*) = 0 \cr
&amp; f(\mu^* k^*) = c^* + k^* \delta \mu^{* \alpha} \cr
\end{align}$$</p>

<p>The first condition there is the <a href="http://www.dictionaryofeconomics.com/article?id=pde2008_E000287">Euler-Ramsey Condition (ERC)</a> for this problem. </p>

<h3 id="existence-and-uniqueness">Existence and Uniqueness</h3>

<p>Under what conditions would the steady state exist and be unique? We can consider this in two cases: full capacity utilization and partial capacity utilization.</p>

<p><strong>Full capacity utilization</strong></p>

<p>In this case, \( \mu^* = 1 , \gamma_5^* \ge 0 \). From the ERC, we get that</p>

<p>$$ f^k ( k^*) = \beta^{-1} + \delta - 1 $$</p>

<p>If we assume that \( f^k ( k^*) \) is such that</p>

<p>$$\begin{align}
\lim_{k \to 0} \beta ( f^k ( k^*) - \delta + 1 ) \gt &amp; 1 \cr<br>
\lim_{k \to \infty} \beta ( f^k ( k^*) - \delta + 1 ) \lt &amp; 1 \cr<br>
\end{align}$$</p>

<p>then strict concavity and twice continuous differentiability of \( f \) guarantee existence and uniqueness of the steady state. I think this would be considered a corner solution of the model.</p>

<p>What is consumption in this case? The fourth steady state condition tells us that \( c^* = f(k^* ) - k^* \delta \), and the ERC tells us that \( f(k^* ) - \delta = \beta^{-1} - 1 \gt 0 \). So consumption is something strictly positive whenever it is optimal to utilize capacity fully.</p>

<p><strong>Partial capacity utilization</strong></p>

<p>In this case, \( \mu^* \lt 1 , \gamma_5^* = 0 \). This is a fully interior solution, and at the steady state \( f^{\mu} = f^k \) (equal marginal utility of inputs). From the ERC, we get that</p>

<p>$$ \mu^* = \left[ \left( \frac{1- \beta}{\beta} \right) \left( \frac{1}{\delta (\alpha - 1)} \right) \right]^{\frac{1}{\alpha}} $$</p>

<p>\( \mu^* \) exists as long as </p>

<p>$$ \left( \frac{1- \beta}{\beta} \right) \left( \frac{1}{\delta (\alpha - 1)} \right) \lt 1 $$</p>

<p>The second steady state condition pins down the marginal utility of capacity utilization through the depreciation rate. Formally, \( f^{\mu} ( \mu^* k^*) = \delta \alpha \mu^{* \alpha - 1} \). If we further assume</p>

<p>$$ \lim_{k \to 0} f^k ( \mu k ) = \infty $$</p>

<p>then we get that \( k^* \) exists \( \forall \mu \lt 1 \).</p>

<p>What is consumption in this case? The fourth steady state condition tells us that \( c^* = f( \mu^* k^* ) - k^* \delta \mu^{* \alpha} \). At the steady state, we know that \( f( \mu^* k^* ) \gt k^* \delta \mu^{* \alpha} \) - the optimal solution is such that the level of output is greater than the amount of depreciated utilized capital in each period. So consumption is also strictly positive when it is optimal to partially utilize capacity.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/18/risky-good-supply-passthrough/">
        Optimal quantity supply and pass-through of a risky commodity in a symmetric market
      </a>
    </h1>

    <span class="post-date">18 Oct 2015</span>

    <p>This post is a model I&#39;ve been thinking about a bit lately. Consider a Cournot market with \(n\) symmetric firms competing. Since the firms are symmetric, they will all supply the same quantity, \(\bar{x}\). The firms face a generic inverse demand function, \(P(X)\). The twist is that there is a risk of removal: with probability \(F(n \bar{x} ) \) a firm will randomly be removed from the market. The PDF of removal is \( F&#39;(X) = f&#39;(X) \), which is thrice continuously differentiable.</p>

<p>With this model, I am trying to understand markets for illegal commodities better. I think this is a reasonable way to look at the probability of getting arrested when supplying some prohibited (&quot;risky&quot;) commodity. The chance the seller (&quot;the firm&quot;) gets arrested (removed from the market, 0 payoff) should depend on the number of sellers and the quantity supplied by the individual seller. In this version, it depends on both through aggregate supply. Aggregate quantity supplied is \( X = n \bar{x} \).</p>

<p>I&#39;m not sure I like this; I would like to do it with the probability of removal as a generic function of number of sellers and individual seller&#39;s quantity supplied, \(F(x_i , n) \). But this is tractable and a reasonable start.</p>

<h3 id="optimal-supply-and-profits">Optimal supply and profits</h3>

<p>Each firm solves</p>

<p>$$ \max_x~ F(X)(0) + (1-F(nx))(p(nx)-c)x $$</p>

<p>Their first-order condition is</p>

<p>$$\begin{align} 
&amp; x[np&#39;(X) - nf(X)p(X) - nF(X)p&#39;(X) + cnf(X)] \cr 
&amp; + (p(X)-c)(1-F(X)) = 0 \cr
\end{align}$$</p>

<p>Which gives us the optimal quantity supplied</p>

<p>$$ \bar{x} = \frac{-(p(X) - c)}{n[p&#39;(X) + \frac{f(X)}{1-F(X)}(p(X)-c)]} $$</p>

<p>\( \lambda(X) \equiv \frac{f(X)}{1-F(X)} \) is the arrest hazard rate - the probability of a firm&#39;s arrest for a specific level of aggregate supply given the firm has not been arrested yet. The optimal quantity supplied is reduced from the usual optimal Cournot quantity. The reduction is increasing in the hazard rate (riskier at current \(X\) means sell less to be safe) and the profit margin (more profit per unit means the firm can sell fewer units).</p>

<p>Individual firms&#39; profits are given by</p>

<p>$$ \bar{\pi} = \frac{(p(X) - c)^2 }{n \ [ |p&#39;(X)| + \lambda(X) (p(X)-c)]} $$</p>

<h3 id="pass-through">Pass-through</h3>

<p>How does having this risk in the picture change how cost affects price?</p>

<p>\( \sigma(X) = -\frac{XP&#39;&#39;(X)}{P&#39;(X)} \) is the curvature of the inverse demand function. Define \( \gamma(X) = -\frac{XF&#39;&#39;(X)}{F&#39;(X)} \), the curvature of the arrest likelihood. The pass-through depends on \( \sigma(X)\), \( \gamma(X)\), and \( \lambda(X) \).</p>

<p>Let the firms&#39; first-order condition be \(R\). \(R\) defines the quantity supplied as an implicit function of cost. The quantity pass-through, \(\frac{\partial X}{\partial c}\), is</p>

<p>$$ \begin{align}
 \frac{\partial X}{\partial c} &amp; = - \frac{\partial R / \partial c}{\partial R / \partial X} \cr
\end{align} $$</p>

<p>Then</p>

<p>$$ \begin{align}
\frac{\partial P(X)}{\partial c} &amp; = \frac{\partial P}{\partial X}\frac{\partial X}{\partial c} \cr
\implies \frac{\partial P(X)}{\partial c} &amp; = \frac{Xf(X) + F(X)}{f(X)[2 \lambda^{-1} - 2x - 1 - \sigma \lambda^{-1} - p&#39;^{-1}((p-c)(1- \gamma + ( \gamma / X) ) + p)]}  \cr
\end{align} $$</p>

<p>I&#39;m not sure of my algebra, so I&#39;ll try again and update this. But the terms in the expression make some sense to me. I&#39;m not sure what the derivative wrt the parameters are or if they make sense yet, but that would be an informative exercise.</p>

<h3 id="summary">Summary</h3>

<p>I say &quot;arrest&quot;, but I guess it&#39;s really &quot;zero payoff&quot;. Maybe arrest should be negative payoff or something. I think this could apply to any event, with the payoffs associated with \(F(x)\) set up appropriately. I&#39;m sure this has been done much more generally before.</p>

<p>I think it would be interesting to see the &quot;risk pass-through&quot;, the change in price with respect to risk. The regular passthrough already incorporates the curvature of the risk likelihood, so maybe &quot;risk pass-through&quot; is unnecessary.</p>

<p>I haven&#39;t assumed a form for price here, but it would depend on the hazard rate through \( \bar{x} \). The direct effect of the number of sellers would cancel out of the price, but \(n\) would still come in through the price and risk functions. As the hazard rate increases, I think the price should also increase if only because the quantity supplied will decrease. Without assuming a specific form, I can&#39;t go further in saying much about the price. I would like to see what the arrest risk premium looks like, if it is there.</p>

<p>At some point I may try to do some numerics on this model to see how stuff changes with different assumptions.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/15/principal-agent-problem-owner-manager/">
        A principal-agent problem between an owner and a manager
      </a>
    </h1>

    <span class="post-date">15 Oct 2015</span>

    <p>Suppose a firm&#39;s owner contracts a manager to run the firm. The firm&#39;s profit is a random variable \(\pi \in [\pi_a , \pi_b]\)  which the manager can influence through some effort. For simplicity, assume effort is discrete: \(e \in \{e_l,e_h\}\), with \(e_h \gt e_l \ge 0 \).  The manager&#39;s efforts are such that profits with \(e_h\) first-order stochastically dominate profits with \(e_l\), i.e. \(E \ [\pi|e_h] \gt E \ [\pi|e_l]\) and \( f(\pi|e) \gt 0 ~~ \forall \pi\). The manager&#39;s utility is \(u(w,e) = v(w) - g(e)\) with \(g(e_h) \gt g(e_l) \) and \(v&#39;(w) \gt 0, v&#39;&#39;(w) \lt 0\). The manager&#39;s utility strictly concave, so they are risk-averse. Let&#39;s assume the manager&#39;s reservation utility is \(\bar{u} \ge 0 \).</p>

<p>The idea is that the manager would prefer to exert less effort to more, but that more effort is likely to produce higher profits than less effort. No manager can control everything - profit is still a random variable and low realizations can occur when the manager exerts more effort, it&#39;s just less likely. The manager&#39;s reservaton utility is their outside offer or what they could produce at home. For clarity, let&#39;s call the owner she and the manager he.</p>

<h4 id="benchmark-case-effort-is-publicly-observable">Benchmark case: effort is publicly observable</h4>

<p>If the manager&#39;s efforts are publicly observable, then the owner solves</p>

<p>$$ \begin{align}
\max_{e \in \{e_l, e_h \}, w( \pi )} ~~&amp; \int_{\pi_a}^{\pi_b} [\pi - w( \pi )] f(\pi | e) ~ d \pi \cr
\text{s.t.} ~~&amp; \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \ge \bar{u}
\end{align} $$</p>

<p>We can think of this as a two-stage decision process: given some level of effort from the manager, the owner wants to pay him the profit-maximizing wage. The constraint is called an &quot;individual rationality (IR) constraint&quot; or a &quot;participation constraint&quot;. It&#39;s a way to factor the manager&#39;s problem into the owner&#39;s decision-making - the owner is constrained to pay the manager a wage that is at least as good as the manager&#39;s outside offer. If the owner doesn&#39;t, the manager won&#39;t work for her. For a fixed level of effort \(e\), the owner&#39;s problem can be simplified to minimizing the manager&#39;s wage subject to the participation constraint, or maximizing the negative of the manager&#39;s wage.</p>

<p>$$ \begin{align}
\min_{w( \pi )} ~~&amp; \int_{\pi_a}^{\pi_b} w( \pi ) f(\pi | e) ~ d \pi \cr
\text{s.t.} ~~&amp; \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \ge \bar{u}
\end{align} $$</p>

<p>A minimization problem can be made into a maximization problem by multiplying the objective by \(-1\). Economists seem to prefer maximization, while statisticians and computer scientists seem to prefer minimization. I&#39;m not sure why this is the case, or if it even is the case beyond my limited sample. </p>

<p>Since we integrated over \(\pi\) this wage holds for all realizations of profit. We can solve this as a constrained maximization</p>

<p>$$ \begin{align}
\mathcal{L} = &amp; - \int_{\pi_a}^{\pi_b} w( \pi ) f(\pi | e) ~ d \pi + \lambda [\int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) - \bar{u}] \cr
\text{FOC:} ~~ &amp; - \int_{\pi_a}^{\pi_b} f(\pi | e) ~ d \pi + \lambda \int_{\pi_a}^{\pi_b} v&#39;(w(\pi )) f(\pi | e) ~ d \pi = 0 \cr
\implies ~~ &amp; \frac{1}{v&#39;(w(\pi ))} = \lambda
\end{align} $$</p>

<p>From this we see that for a given level of effort, the optimal wage must be a constant. The optimal wage profile for any level of effort is to pay the manager the inverse wage-utility of the sum of their reservation utility and their marginal cost of effort, or \(w^*_e = v^{-1}(\bar{u} + g(e)) \). We can think of this as insurance against profit risk: the optimal contract will insure the risk-averse manager against any realization of profit, since the manager&#39;s effort doesn&#39;t guarantee high profits, just makes it more likely.</p>

<p>The lagrange multiplier \( \lambda\) on the participation constraint is the owner&#39;s <a href="https://en.wikipedia.org/wiki/Shadow_price">shadow price</a> of the manager&#39;s participation: it&#39;s the owner&#39;s (maximum) willingness-to-pay to marginally reduce the manager&#39;s reservation utility. More generally, the lagrange multiplier on a constraint is the improvement to the objective function from marginally relaxing that constraint.</p>

<p>The IR constraint must bind in this problem if the manager works for the owner. Any excess utility the owner gives the manager reduces the owner&#39;s profit, so the owner can always do better by reducing the manager&#39;s wage until the constraint binds.</p>

<h4 id="information-problem-effort-is-manager-39-s-private-information">Information problem: effort is manager&#39;s private information</h4>

<p>Now suppose the manager&#39;s effort level is not publicly observable anymore, it&#39;s the manager&#39;s private information. Now the owner solves</p>

<p>$$ \begin{align}
\min_{w( \pi )} ~~&amp; \int_{\pi_a}^{\pi_b} w( \pi ) f(\pi | e) ~ d \pi \cr
\text{s.t.} ~~&amp; \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \ge \bar{u} \cr
&amp; e = \text{argmax} ~~ \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \cr
\end{align} $$</p>

<p>The second constraint is called an &quot;incentive compatibility&quot; (IC) constraint. It says that the effort level the owner wants to implement has to be solve the manager&#39;s problem. I think of this as a refinement on the IR constraint - not only should it make sense for the manager to participate, it should be what they would most prefer to do. The manager should have no incentive to deviate. It&#39;s not quite the same as the IR constraint, since it&#39;s possible for the argmax of the manager&#39;s problem under effort is lower than the reservation utility.</p>

<p>Implementing \(e_l\) is easy - the owner just pays the manager the same wage as under observable effort. It satisfies the IR constraint, and at that wage the manager would put in low effort anyway (there is no profitable deviation). Implementing \(e_h\) is more interesting, since the IC constraint becomes important. For this problem, the IC implies</p>

<p>$$ \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e_h ) ~ d \pi - g(e_h ) \ge \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e_l ) ~ d \pi - g(e_l ) $$</p>

<p>So the manager&#39;s expected value of putting in high effort has to be greater than or equal to his expected value of putting in low effort. If not, the manager has an incentive to deviate and since effort is unobservable, he will.</p>

<p>As before, we put it into a lagrangian. From the first-order condition of the owner&#39;s problem,</p>

<p>$$\begin{align}
w(\pi) : ~~ &amp; - \int_{\pi_a}^{\pi_b} f(\pi | e_h ) ~ d \pi + \lambda  \int_{\pi_a}^{\pi_b} v&#39;(w(\pi )) f(\pi | e_h ) ~ d\pi \cr + \ &amp; \gamma \int_{\pi_a}^{\pi_b} [f(\pi | e_h )-f(\pi | e_l )] \ v&#39;(w(\pi)) = 0 \cr
\implies ~~ &amp; \frac{1}{v&#39;(w(\pi ))} = \lambda + \gamma \left[ 1 - \frac{f(\pi|e_l )}{f(\pi|e_h )} \right]
\end{align}$$</p>

<p>The condition on the wage has the same component of the IR constraint multiplier - the shadow price of the manager&#39;s participation - and a new component from the IC constraint based on the shadow price of the manager&#39;s cooperation. This component is not a constant - it depends on the realizations of profit through the ratio of conditional densities of profit given effort. In repeated play, this term is a likelihood ratio. </p>

<p>By the same argument as earlier, the IR constraint must bind. By a similar argument, the IC constraint will also bind if high effort is implemented.</p>

<p>The cooperation shadow price is scaled based on the likelihood ratio of observed profits given effort, i.e. based on how likely the observed profits were given the efforts the manager could have exerted. I&#39;m not sure how to do this if effort were continuous; maybe a conditional expectation? </p>

<p>If the manager cooperates and doesn&#39;t shirk, the second component can be nearly as large as the owner&#39;s shadow price on cooperation (because the densities are strictly positive on the support, the likelihood ratio can be small but not 0). However, profits are random, and low realizations will affect the manager&#39;s pay - low realizations are just less likely when the manager is cooperating. I see the way the likelihood ratio enters as an &quot;information penalty&quot;. Without further restrictions, the penalty may cause the wage to be negative. I think this is unrealistic, but my guess is that adding a wage nonnegativity constraint will penalize the manager&#39;s wage, since the owner can&#39;t optimally punish the manager for bad profit realizations. I should try that.</p>

<p>My guess is that there is some connection between this information penalty and how much information is contained in the conditional distributions, or how sensitive profits are to efforts. I think that in the limiting case of the conditional distribution of profits being uniform for any effort level, the second term in the optimal wage would disappear. In that case, the owner would only pay the manager enough to participate, but since the owner has no information to check on the manager&#39;s effort levels, the owner won&#39;t pay the manager anything for exerting effort. In that case, I don&#39;t think an equilibrium where the manager exerts high effort can be sustained.</p>

<p>In the other direction, if the conditional distributions are highly informative about effort levels, then the penalties will be applied much more swiftly and harshly but also much less often if the manager is cooperating.</p>

<p>The information penalty also seems related to the <a href="https://en.wikipedia.org/wiki/Price_of_anarchy">Price of Anarchy</a>, like maybe a &quot;likelihood-PoA&quot; or something. I wonder if that&#39;s a thing.</p>

<p>It would be interesting to see a critical discount rate for the manager&#39;s cooperation in a dynamic version of this, given that he may be penalized even if he cooperates.</p>

<h4 id="conclusion">Conclusion</h4>

<p>This model is like my earlier attempt to model an owner-manager problem combined with the labor market signaling problem. Unlike the earlier problem, here the manager&#39;s behavior is embedded in the owner&#39;s problem as a constraint. This problem also abstracts away from the actual generation of profits - the owner in this problem only sees profits as a random variable, not as actual revenues and costs. This lets us get effort into the problem, which lets us drive a wedge between the owner and the manager. Given the manager&#39;s incentive compatibility constraint, it seems like low realizations of profits could cause the manager to shirk, but I&#39;m not sure if that&#39;s true.</p>

<p>The initial assumptions are somewhat strict, and it makes sense to change them based on the specific question at hand. One example I&#39;ve been thinking of is a mutual fund manager principal-agent problem. The owner would be the investor (the manager&#39;s client), the profits would be the mutual fund&#39;s returns, and effort would be trading activity. Many mutual funds charge commissions for &quot;active management&quot;, but generally portfolio returns are higher under &quot;passive management&quot;. This would require reversing our earlier assumptions about effort and the conditional distribution of profits given effort. In the benchmark case, we can imagine the investor is choosing between an actively managed fund versus a passively managed one. When the trading activity is hidden information, then there would probably be a condition very similar to the incentive compatibility constraint here that would scale the manager&#39;s pay based on observed portfolio returns, with a penalty for excess trading. </p>

<p>What if the principal doesn&#39;t know the conditional distribution of payoffs given the agent&#39;s actions? One way to model that could be as a Bayesian game - the principal has some beliefs over the distribution, and learns from repeated play.</p>

<p>I like this model a lot. The problems aren&#39;t hard to solve, but the way they go together makes the model do interesting things. The initial assumptions are important, but it is reasonable to change them and try things. I think these features make a model fun to play with. I wonder how well its predictions have held up if/when they&#39;ve been put to the data.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/12/eu-max-3-lottery/">
        An expected-utility maximizer and 3 lotteries
      </a>
    </h1>

    <span class="post-date">12 Oct 2015</span>

    <p>Consider an individual with preferences over lotteries that have an expected-utility representation. There are three lotteries this individual can choose from:</p>

<p>$$ L_1
\begin{cases}
\begin{align}
200 ~~~ &amp;P(200) = 1 \cr
\end{align}
\end{cases}$$</p>

<p>$$ L_2
\begin{cases}
\begin{align}
0 ~~~ &amp;P(0) = 2/3 \cr
200 ~~~ &amp;P(200) = 1/6 \cr
1000 ~~~ &amp;P(1000) = 1/6 \cr
\end{align}
\end{cases}$$</p>

<p>$$ L_3
\begin{cases}
\begin{align}
0 ~~~ &amp;P(0) = 1/3 \cr
400 ~~~ &amp;P(400) = 1/3 \cr
1000 ~~~ &amp;P(1000) = 1/3 \cr
\end{align}
\end{cases}$$</p>

<p>The expected utilities of the lotteries are:</p>

<p>$$\begin{align}
EU_{L1} =&amp; (200)(1) = 200 \cr
EU_{L2} =&amp; (0)(1/3) + (100)(1/6) + (1000)(1/6) \cr
 =&amp; 200 \cr
 EU_{L3} =&amp; (0)(1/3) + (100)(1/3) + (1000)(1/3) \cr
 =&amp; 1400/3 \cr
\end{align}$$</p>

<p>We can take a first pass at ordering the three lotteries by expected utility alone. This gives us that \( L_3 \succ L_2 \sim L_1\). To go further, we can use the concept of <a href="https://en.wikipedia.org/wiki/Stochastic_dominance">stochastic dominance</a>.</p>

<p>\(X \succ_{FSD} Y\) (X first-order stochastically dominates Y) if \(F_x (t) \le F_y (t) ~ \forall t \in [a,b]\), where \([a,b]\) is the support of \(F_x\) and \(F_y\). This is equivalent to saying \(X \succ_{FSD} Y\) iff \( E[u(x)] \ge E[u(y)] ~ \forall\) nondecreasing, continuous functions \(u\). We apply this concept when we order the lotteries by expected utility.</p>

<p>Second-order stochastic dominance is a refinement on this. We say \(X \succ_{SSD} Y\) (X second-order stochastically dominates Y) if \(\int_a^w F_x (t) dt \le \int_a^w F_y (t) dt ~ \forall w \in [a,b]\), where \([a,b]\) is the support of \(F_x\) and \(F_y\). This is equivalent to saying \(X \succ_{SSD} Y\) iff \( E[u(x)] \ge E[u(y)] ~ \forall\) nondecreasing, continuous, and <em>concave</em> functions \(u\). We apply this concept when we order the lotteries by expected utility.</p>

<p>If all we have is that the agent is an expected-utility maximizer then all we can do is apply first-order stochastic dominance and say that the agent will prefer \(L_3\) over \(L_1\) and \(L_2\), and be indifferent between \(L_1\) and \(L_2\).</p>

<p>If we know or are willing to assume that the agent is risk-averse - that their utility function \(u\) is concave - then we can apply second-order stochastic dominance and rank the lotteries \(L_3 \succ L_1 \succ L_2 \). The risk-averse agent would rather take the safe 200-for-sure than the risky 200-on-average.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/11/monopoly-pricing-discrete-sequential-demand/">
        Monopoly pricing for sequential discrete demand
      </a>
    </h1>

    <span class="post-date">11 Oct 2015</span>

    <p>Today&#39;s post is a variation on <a href="http://akhilrao.github.io/micro%20theory/2015/10/04/monopoly-pricing-discrete-demand/">monopoly pricing for discrete demand</a>.</p>

<p>Suppose you&#39;re moving, and you have a piece of used furniture that you need to sell. You&#39;ve got two potential buyers, \(B_1\) and \(B_2\), lined up to buy it. They arrive sequentially, so \(B_2\) won&#39;t have anything to look at if \(B_1\) buys. Assume \(B_i\) is willing to pay \(v_i\) for the furniture, where \(v_i\) is an independent draw from a uniform CDF \(F(v_i) = \frac{v_i - a}{b - a}\) for \(v_i \in [a,b]\). The furniture has no value to you if it isn&#39;t sold - you can&#39;t take it with you - and there is no discounting. There&#39;s no bargaining, either - you get to make a take-it-or-leave-it offer to each buyer.</p>

<p>Let&#39;s start at the end of this game with some numbers: \(a=40, b=140\).</p>

<h4 id="pricing-for-the-second-buyer">Pricing for the second buyer</h4>

<p>Suppose \(B_1\) rejected your offer, so you&#39;re pricing it for \(B_2\). The game ends if this buyer rejects, so this round is basically a standard discrete demand monopoly pricing problem. Your price solves</p>

<p>$$ \max_{p_2} ~ (p_2-c)(1-F(p_2)) $$</p>

<p>Giving us</p>

<p>$$ p_2 = c + \frac{1-F(p_2 )}{f(p_2 )} $$</p>

<p>In this example, the marginal cost would be the opportunity cost - the value of the furniture to you if you didn&#39;t sell it. We know that&#39;s 0 here because you&#39;re moving and can&#39;t take it with you. Plugging in for this uniform CDF and PDF, the optimal price becomes</p>

<p>$$\begin{align}
 p_2 &amp;= \frac{b}{2} \cr
\implies p_2 &amp;= 70 \cr
\end{align} $$</p>

<p>Your expected profits from this pricing scheme are</p>

<p>$$\begin{align}
\pi_2 &amp;= (p_2-c)(1-F(p_2)) \cr
&amp;= (70)(\frac{70}{100}) \cr
&amp;= 49 \cr 
\end{align}$$</p>

<p>Note that there&#39;s no discounting here - if there was, we&#39;d be hitting this expected profit with a discount rate, and it would be lower than 49.</p>

<h4 id="pricing-for-the-first-buyer">Pricing for the first buyer</h4>

<p>Now that we know the end of the game, we can go backwards to the first round. You&#39;re solving the same problem for the first buyer, but now you have to keep in mind that if the first person doesn&#39;t buy, you&#39;ve still got the second person coming. The optimal price will solve</p>

<p>$$ \max_{p_1} ~ p_1(1-F(p_1)) + F(p_1) \pi_2 $$</p>

<p>Giving us</p>

<p>$$ p_1 = \frac{189}{2} \gt p_2 $$</p>

<p>This is nice and what we would expect: when you have multiple buyers lined up, your price should decrease over time as buyers reject, if only because there are fewer buyers coming later. The last buyer should receive the lowest price.</p>

<p>To round it off, your expected profits in the first stage would be 73.7975. Your expected profits decrease as you move through the buyers, since your price gets lower and you lose the expected value of the future buyers.</p>

<p>Adding discounting wouldn&#39;t change the key features of this problem. Adding bargaining would, since the buyers wouldn&#39;t have to accept your profit-maximizing price. Discounting plus bargaining would change things by giving the person with the higher discount rate (more patience) an advantage. This is what happens in Rubinstein bargaining games.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>



<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
