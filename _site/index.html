<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      A Model A Day &middot; By Akhil Rao
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          A Model A Day
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/archive/">Archive</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/akhilrao/archive/v0.0.1.zip">Download</a>
      <a class="sidebar-nav-item" href="https://github.com/akhilrao">GitHub project</a>
      <span class="sidebar-nav-item">Currently v0.0.1</span>
    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/06/labor-market-signalling-two-types/">
        A simple labor market with two types of workers and a test
      </a>
    </h1>

    <span class="post-date">06 Oct 2015</span>

    <p>Consider a competitive labor market where workers are either high ability (&quot;high type&quot;) or low ability (&quot;low type&quot;). A worker&#39;s type is the worker&#39;s private information, but the firms are aware that a fraction \(\alpha \in (0,1)\) of the workers have high ability. The high ability worker will produce value \(v=v_h\) for the firm, and the low type will produce \(v=v_l\), where \(0\le v_l\lt v_h\lt\infty\). The worker&#39;s can produce \(r\lt v_h\) if they are self-employed (reservation wage).</p>

<h4 id="benchmark-case-no-signalling">Benchmark case: No signalling</h4>

<p>If there&#39;s no way for the worker to signal their type to the firm, then the firm will go with what it knows: that the probability of a worker having high ability is \(\alpha\). Using this, we get that the firm&#39;s expectation of the workers&#39; ability is \(E[v]=\alpha v_h + (1-\alpha) v_l\).</p>

<p>A <a href="https://en.wikipedia.org/wiki/Competitive_equilibrium">competitive equilibrium</a> can be described be a price \(w^*(\theta)\) and an allocation \(\theta^*(w)\) which maximize the agents&#39; expected utilities. Here, the CE is</p>

<p>$$\begin{align}
w^*(\theta)=E \ [ \ \theta \ | \ \theta \in \theta^*] \cr
\theta^*(w)= \{ \theta \ : \ r \le w \}
\end{align}$$</p>

<p>The firm will pay workers the expected value of their marginal productivity, which ends up being a constant. The workers will work if the wage is greater than or equal to what they could get staying at home. If the workers&#39; reservation wage is greater than the firm&#39;s wage (expected marginal productivity of labor), no one will work. If \(r&lt;w=E[v]\), everyone will work.</p>

<h4 id="with-a-costly-test-that-signals-types">With a costly test that signals types</h4>

<p>Now suppose there&#39;s a test that workers can take, and it&#39;s easier for high types to get a certain score than it is for low types. By observing the score that workers get on the test, firms can guess whether a worker is high ability or not. Formally,</p>

<p>$$c(e,\theta)=
\begin{cases}
c_{h}e ~~~ \text{if} ~ \theta=v_h \cr
c_{l}e ~~~ \text{if} ~ \theta=v_l
\end{cases}$$</p>

<p>where \(0\lt c_h\lt c_l\). Preparing for and taking the test is useless except that it is costlier for the low type, and can be used to distinguish between the types.</p>

<p>The equilibrium concept we use here is a Perfect Bayesian Equilibrium (<a href="https://en.wikipedia.org/wiki/Bayesian_game#Perfect_Bayesian_equilibrium">PBE</a>. The worker&#39;s choice of test score is optimal given their knowledge of their type, the firm&#39;s beliefs of the worker&#39;s type after observing their test score \(\mu(e)\) is formed using Bayes&#39; Rule, and the wage \(w(e)\) is a Nash equilibrium for \(e(\theta)\) given the firm&#39;s beliefs \(\mu(e)\).</p>

<p>One separating PBE that we can construct is \(w^*(e^*(v_h)) = v_h\) and \(w^*(e^*(v_l)) = v_l\), \(e^*(v_l)=0\), and \(e^*(v_h)=\tilde{e}\), where \(\tilde{e}\) is the least education the high type can get while still getting utility at least as high as if they pooled with the low type. </p>

<p>The argument for this is pretty simple. If the high type can signal their ability, there&#39;s no point in the low type scoring above 0 on the test - effort is costly. If the firm can distinguish high and low types, then they will pay each their marginal product.</p>

<p>The most efficient separating PBE is when the high type engages in as little signalling behavior as possible. This occurs when the high type&#39;s education level makes them indifferent between being employed and pooling with the low type. Letting \(c_l(e)=c(e,v_l)\) and \(c_h(e)=c(e,v_h)\),</p>

<p>$$\begin{align}
e^*(v_h):&amp;~~ v_h - c_l (e^*(v_h)) = v_l \cr
\implies &amp;~ c_l (e^*(v_h)) = v_h-v_l \cr
\implies &amp;~ e^*(v_h) = c_l^{-1}(v_h-v_l) \equiv \tilde{e} \cr
\end{align}$$</p>

<p>The full PBE is</p>

<p>$$ e^*(\theta) =
\begin{cases}
0 ~~ \text{if} ~~ \theta=v_l\cr
\tilde{e} ~~ \text{if} ~~ \theta=v_h\cr
\end{cases} $$</p>

<p>$$ \mu^*(e) =
\begin{cases}
0 ~~ \text{if} ~~ e \lt \tilde{e}\cr
1 ~~ \text{if} ~~ e \ge \tilde{e}\cr
\end{cases} $$</p>

<p>$$ w^*(e) =
\begin{cases}
v_l ~~ \text{if} ~~ \theta=v_l\cr
v_h ~~ \text{if} ~~ \theta=v_h\cr
\end{cases} $$</p>

<p>This is not a unique equilibrium. There are a continuum of separating PBEs that are less efficient than this one, and a continuum of pooling PBEs with one more efficient than the rest. Whether the most efficient separating PBE is more efficient than the most efficient pooling PBE depends on the parameter values.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/05/hotelling-circle-city/">
        A symmetric Circle City Hotelling model
      </a>
    </h1>

    <span class="post-date">05 Oct 2015</span>

    <p>This model is very similar to <a href="">Triangle City</a>.</p>

<h3 id="circle-city">Circle City</h3>

<p>Let the circle be of circumference \(d\pi\). There are \(n\) symmetric firms facing marginal cost \(c\) located equidistant from each other on the circle. Firm \(i\) faces two marginal consumers: \(x_{i-1}\) (the firm to its left) and \(x_i\) (the firm to its right). The marginal consumers are identical, and firm \(i\) and firm \(i+1\) compete over consumer \(x_i\). Consumers face a travel cost of t. \(x_i\)&#39;s utility is given by:</p>

<p>$$\begin{align} 
v - p_i - tx_i &amp;= v - p_{i+1} - t(\frac{td\pi}{n}-x_i) \cr
\implies x_i &amp;= \frac{p_{i+1}-p_i+(td\pi/n)}{2t} \cr
\end{align}$$</p>

<p>Since the consumers are identical, this holds for every marginal consumer. Firm \(i\) faces \(x_i + x_{i-1}\), and solves</p>

<p>$$max_p (p_i-c)\left[\frac{p_{i+1}-p_i+(td\pi/n)}{2t} + \frac{p_{i-1}-p_i+(td\pi/n)}{2t} \right] $$</p>

<p>$$\begin{align} 
\text{FOC:} &amp;~~~ \left[\frac{p_{i+1}-p_i+(td\pi/n)}{2t} + \frac{p_{i-1}-p_i+(td\pi/n)}{2t} \right] - (p_i-c)\frac{2}{2t} \cr
\implies &amp; ~~~ \frac{td\pi}{n} - (p_i-c)\frac{1}{t} = 0 ~~~~~~ (\pi_i=\pi_j ~ \forall~i,j~\because \text{firms are symmetric})\cr
\implies &amp; p_i^* = c + \frac{td\pi}{n}
\end{align}$$</p>

<p>So the markup is increasing in the diameter of the circle (\(\frac{\partial p}{\partial d} \gt 0\)) and the travel cost (\(\frac{\partial p}{\partial } \gt 0\)), and decreasing in the number of firms (\(n \to \infty\), \(p \to c\)).</p>

<p>The fact that firm \(i\) faces 2 (or \(k\), I suppose) symmetric marginal customers doesn&#39;t affect the equilibrium prices \(p_i^*\), only equilibrium profits \(\pi_i^*\) (scaled by \(k\)).</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/05/asymmetric-cournot-discrete-quantities/">
        Asymmetric Cournot with discrete quantities
      </a>
    </h1>

    <span class="post-date">05 Oct 2015</span>

    <p>In standard Cournot models, firms are symmetric and choose continuous quantities (\(q_i \in \mathbb{R_+}\)). Here we consider a model of Cournot duopoly with asymmetric firms limited to discrete quantities (\(q_i \in \mathbb{Z_+}\)). Because the set we are optimizing over is no longer continuous, we can&#39;t use the Kuhn-Tucker approach used in Cournot models with continuous quantities. Instead, we set up the problem as a game in <a href="https://en.wikipedia.org/wiki/Normal-form_game">normal form</a> and find the pure- and mixed-strategy Nash equilibria by using <a href="https://en.wikipedia.org/wiki/Strategic_dominance">iterated elimination of dominated strategies</a>.</p>

<h3 id="the-setting">The setting</h3>

<p>Let firm 1 have marginal cost \(c_1 = 4\) and firm 2 have marginal cost \(c_2 = 5\). Let the inverse demand function be given by 
$$ \begin{align}
P(Q)=\begin{cases} 10 - Q \ \ &amp; if \ \ Q \le 10 \cr 
0 \ \ &amp; if \ \ Q \gt 10 \end{cases} 
\end{align} $$</p>

<p>and \( Q = q_1 + q_2\).</p>

<p>To start, we can eliminate any quantities greater than the firm&#39;s monopoly quantities. That&#39;s what the firm would do if it wasn&#39;t constrained by its competitor, so it can&#39;t be profit-maximizing to play anything above those quantities. To find the monopoly quantities, we can take the standard Cournot duopoly best-response function, \(q_i^* = \frac{a - bq_j^* - c_i}{2b}\), and plug in \( q_j^* = 0\). This gives us that firm 1&#39;s monopoly quantity is 3, and firm 2&#39;s is 2.5. We can eliminate any quantity choice greater than 3 for both firms, since they are strictly dominated.</p>

<p>How do we handle 2.5? Firm 2 has to choose 2 or 3, not 2.5. We can see that \(\pi_2(q_1=0,q_2=3) = 6\) and \(\pi_2(q_1=0,q_2=2) = 6 \), so we can&#39;t eliminate 3 from firm 2&#39;s choices by strict domination.</p>

<p>The game matrix below shows the firms&#39; profits. Firm 1 is on the columns, and firm 2 is on the rows. The entries are &quot;\(\pi_1, \pi_2\)&quot;.</p>

<p>$$\begin{array}{c|lcr}
 &amp; 0 &amp; 1 &amp; 2 &amp; 3 \cr
\hline
0 &amp; 0,0 &amp; 5,0 &amp; 8,0 &amp; 9,0 \cr
1 &amp; 0,4 &amp; 4,3 &amp; 6,2 &amp; 6,1 \cr
2 &amp; 0,6 &amp; 3,4 &amp; 4,2 &amp; 3,0 \cr
3 &amp; 0,6 &amp; 2,3 &amp; 2,0 &amp; 0,-3
\end{array}$$</p>

<p>Iterated elimination:</p>

<ul>
<li>Firm 1: 1 strictly dominates 0 \(\implies\) remove 0-column</li>
<li>Firm 2: 2 strictly dominates 3 \(\implies\) remove 3-row</li>
<li>Firm 1: 2 strictly dominates 1 \(\implies\) remove 1-column</li>
<li>Firm 2: 1 strictly dominates 0 \(\implies\) remove 0-row</li>
</ul>

<p>This leaves us with the following 2x2 game matrix:</p>

<p>$$\begin{array}{c|lr}
 &amp; 2 &amp; 3 \cr
\hline
1 &amp; 6,2 &amp; 6,1 \cr
2 &amp; 4,2 &amp; 3,0 \cr
\end{array}$$</p>

<p>There are 3 pure-strategy Nash equilibria, \((q_1,q_2,\pi_1,\pi_2)\):</p>

<ol>
<li>\((2,1,6,2)\)</li>
<li>\((2,2,4,2)\)</li>
<li>\((3,1,6,1)\)</li>
</ol>

<p>Letting \(p_1 = Pr(q_2=1)\), \(p_2 = Pr(q_2=2)\), \(k_2=Pr(q_1=2)\), \(k_3=Pr(q_1=3)\), we can get their expected utilities:</p>

<p>$$\begin{align}
EU_{1}(2) &amp; = p_1(6) + p_2(4) = 6p_1 + 4p_2 \cr
EU_{1}(3) &amp; = p_1(6) + p_2(3) = 6p_1 + 3p_2 \cr
EU_{2}(1) &amp; = k_2(2) + k_3(1) = 2k_2 + k_3 \cr
EU_{2}(2) &amp; = k_2(2) + k_3(0) = 2k_2 \cr
\end{align}$$</p>

<p>By applying expected-utility indifference, we can construct a mixed NE.</p>

<p>$$\begin{align}
EU_1(2) &amp; = EU_1(3) \cr
EU_2(1) &amp; = EU_2(2) \cr
\implies p_2&amp;=0,p_1=1 \cr
 k_3&amp;=0,k_2=1 \cr 
\end{align}$$</p>

<p>This is odd: The mixed NE that&#39;s coming out is a degenerate one, pure NE #1. I think I remember something to the effect that the total number of pure + mixed NE in a matrix game is supposed to be odd, so this might imply that there are actually no mixed NE? I was told that this game actually has infinitely many mixed NE, but I don&#39;t see it.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/04/monopoly-pricing-discrete-demand/">
        Monopoly pricing for discrete demand
      </a>
    </h1>

    <span class="post-date">04 Oct 2015</span>

    <p>How should a monopoly price when demand is discrete? This situation arises whenever the consumer is choosing between &quot;buy&quot; or &quot;not buy&quot;, as opposed to a choice of a continuous quantity.</p>

<p>Let the consumers&#39; valuations of the good be given by \(V \sim F(v)\), where \(F(v)\) is the <a href="https://en.wikipedia.org/wiki/Cumulative_distribution_function">CDF</a> of the valuations and \(f(p)\) is the associated density. The probability that a consumer chooses to buy the good is the probability that their valuation is greater than the price, i.e. \(1-F(p)\). The seller&#39;s expected payoff is then</p>

<p>$$ \pi(p) = (p-c)(1-F(p)) $$</p>

<p>This is the usual profit expression, but with \(1-F(p)\) as the demand. Maximizing this gives us</p>

<p>$$ \begin{align}
 \text{FOC:} \ \ &amp; 1 - F(p) - pf(p) + cf(p) = 0 \cr
 \implies \ \ &amp; p = c + \frac{1-F(p)}{f(p)} \cr
\end{align}$$</p>

<p>This is called &quot;markup pricing&quot;; the price is the marginal cost \(c\) plus a markup, \( \frac{1-F(p)}{f(p)} \). The markup is the inverse of the <a href="https://en.wikipedia.org/wiki/Failure_rate#hazard_function">hazard rate</a> of the demand function. The hazard rate measures how likely an event (a &quot;failure&quot;, or &quot;hazard&quot;) is to happen given that it hasn&#39;t happened before. In the case of demand, the hazard rate is the probability that a consumer will buy the good at a certain price \(p\), conditional on having not bought the good before. So it makes some sense that the markup would be based on the hazard rate of demand.</p>

<h3 id="an-example">An example</h3>

<p>Suppose \( F(v) \sim U[a,b]\) - the consumers are equally likely to be willing to pay anywhere from \(a\) to \(b\) for the product. Then \(F(v) = \frac{v-a}{b-a} \), and \(f(v) = \frac{1}{b-a}\). Plugging this into the pricing formula we derived above, we get</p>

<p>$$\begin{align}
p &amp; = c + \frac{1- \frac{p-a}{b-a}}{\frac{1}{b-a}} \cr
\implies p &amp; = \frac{c+b}{2} \cr
\end{align}$$</p>

<p>So, for uniformly distributed valuations of the product, the monopolist should optimally price their product at half of marginal cost plus the maximum valuation.</p>

<h3 id="more-on-the-hazard-rate">More on the hazard rate</h3>

<p>The hazard rate, \(\lambda\), turns out to be important to analyzing markets. We usually assume that \(\lambda\) is nondecreasing in \(p\). This is equivalent to assuming that the density of demand is log-concave. A proof of the statement follows.</p>

<h5 id="proof">Proof</h5>

<p>$$\begin{align}
f&#39;(x)[1-F(x)] &amp; = \int_x^\infty f&#39;(x)f(t)dt \cr
 &amp; = \int_x^\infty \frac{f&#39;(x)}{f(x)}f(t)f(x)dt \cr
 &amp; \ge \int_x^\infty \frac{f&#39;(t)}{f(t)}f(t)f(x)dt  ~~~~(\because t \ge x) \cr
 &amp; = f(x)[f(\infty) - f(x)]
 &amp; \ge - f(x)^2
\end{align}$$</p>

<p>So log-concave \(f(x) \equiv \lambda\) is nondecreasing. </p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/03/repeated-bertrand-collusion/">
        Repeated play and collusion in an N-firm Bertrand oligopoly
      </a>
    </h1>

    <span class="post-date">03 Oct 2015</span>

    <p>So far, <a href="http://akhilrao.github.io/micro%20theory/2015/09/29/bertrand-cournot-oligopoly/">we&#39;ve seen</a> one-shot Bertrand games with up to \(N\) firms. What happens if the firms are playing a Bertrand game repeatedly for \(T\) periods?</p>

<p>Consider a repeated Bertrand oligopoly with \(N \ge 2\) firms, played for \(T \lt \infty\) periods. We know that the one-shot Nash equilibrium is \(p_{i}=c \ \ \ \forall i \). For \(T\) periods, we start at the last period and work backwards (backwards induction).</p>

<p>In the last period, the game is a one-shot Bertrand game. Thus the equilibrium price will be \(p_{i,T}=c \ \ \ \forall i\). Each firm knows that in period \(T-1\), and  since there&#39;s no possibility of colluding tomorrow they each play \(p_{i,T-1}=c\). We can extend the argument to see that \(p_{i,t}=c \ \ \ \forall t,i\).</p>

<p>What if \(T = \infty\)? If the game is infinitely repeated, we can&#39;t apply backwards induction since there is no last period. Instead, we define trigger strategies and look for parameter restrictions that would need to hold to make the strategy a <a href="https://en.wikipedia.org/wiki/Subgame_perfect_equilibrium">subgame-perfect Nash equilibrium</a>. </p>

<p>Let&#39;s take the same example, and assume that play is history-dependent, i.e. players consider what happened before in deciding what to do today. We&#39;ll consider 3 cases: first when players compete in an infinitely repeated market like above, second when the market as an exogenous probability of ending after each period, and third when firms compete in both markets simultaneously.</p>

<h3 id="case-1">Case 1:</h3>

<p>Suppose players are competing in a market with inverse demand \(D(p)\), call it market A, and have a discount factor \(\delta \lt 1\). The history at any period \(T\) is given by:</p>

<p>$$ H_{T-1} = \{ (p_{i,t}); i=1,2,...,N; t=1,2,...,T-1 \} $$</p>

<p>The <a href="https://en.wikipedia.org/wiki/Trigger_strategy">trigger strategy</a> I define for each player \(i\) to collude is:</p>

<p>$$ p_{i,t} =
\begin{cases}
p_m \ \ \text{if all elements of} \ \ H_{t-1} = p_m, \ \ \text{or if} \ \ t=1 \cr
c \ \ \text{otherwise}
\end{cases} $$</p>

<p>where \(p_m\) is the monopoly price, and \(\pi_m\) is the monopoly profit. We assume that if the firms collude, they do so optimally - they set the price at the monopoly price and divide the profits equally. This is better than pricing at marginal cost and earning 0 profits. But in every period, there is an incentive for firms to deviate and slightly undercut everyone else, capturing the full monopoly profits for one period if they do. However, when they do this everyone goes into the punishment phase and plays \(p=c\), so nobody makes any profits after that. The decision to cooperate or deviate comes down to weighing a stream of discounted payoffs every period against one big payoff today. The discount factor, \(\delta \in (0,1)\) determines how heavily firms weigh future payoffs against present payoffs.</p>

<p>The firms&#39; payoffs from cooperating and deviating optimally are:</p>

<p>$$\begin{align}
\text{Cooperate:} &amp; \ \ \frac{\pi_m}{N} + \delta\frac{\pi_m}{N} + \delta^2\frac{\pi_m}{N} + ... \cr
&amp; = \frac{\pi_m}{N}\frac{1}{1-\delta} \cr \cr
\text{Deviate:} &amp; \ \ \pi_m + 0 + 0 + ... \cr
&amp; = \pi_m \cr
\end{align}$$</p>

<p>To find the minimum \(\delta\) that can support collusion, we set the cooperation payoff to be greater than or equal to the deviation payoff and solve for \(\delta\). This gives us that the critical discount factor is</p>

<p>$$\delta_c \ge \frac{N-1}{N} $$</p>

<p>So as \(N \to \infty\), \(\delta_c \to 1\). When \(N=2, \delta_c \ge \frac{1}{2}\). Collusion becomes harder to sustain when there are more firms, as it requires each firm to weight future payoffs increasingly heavily against current payoffs.</p>

<h3 id="case-2">Case 2:</h3>

<p>In this case, there is an exogenous probability \(\alpha \in (0,1)\) that the market will end after each period. Let&#39;s call this market B. The strategy we defined earlier can be applied here and the deviation payoff is the same, but the cooperation payoff is a little different:</p>

<p>$$\begin{align}
\text{Cooperate:} &amp; \ \ \frac{\pi_m}{N} + \delta(1-\alpha)\frac{\pi_m}{N} + \delta^2(1-\alpha)^2\frac{\pi_m}{N} + ... \cr
&amp; = \frac{\pi_m}{N}\frac{1}{1-\delta(1-\alpha)} \cr
\end{align} $$</p>

<p>Solving for the critical discount factor, we get</p>

<p>$$\delta_c \ge \frac{N-1}{N}\frac{1}{(1-\alpha)} $$</p>

<p>When \(N=2\): </p>

<ul>
<li>\(\alpha\to0 \implies \delta_c \ge \frac{1}{2}\)</li>
<li>\(\alpha=\frac{1}{2} \implies \delta_c \ge 1\)</li>
<li>\(\alpha\to1 \implies \delta_c \ge \infty\)</li>
</ul>

<p>If the market will survive with probability 1, they are as likely to cooperate as in case 1. If the market is 50% or more likely to end tomorrow, they will not cooperate.</p>

<h3 id="case-3">Case 3:</h3>

<p>Finally, what if the firms compete in markets A and B simultaneously? Is collusion more or less likely then? The strategies and payoffs are a bit different here.</p>

<p>The history at time T is: </p>

<p>$$ H_{T-1} = \{ (p_{i,t,A},p_{i,t,B}); i=1,2,...,N; t=1,2,...,T-1\} $$</p>

<p>The trigger strategy I define is:</p>

<p>$$ (p_{i,t,A},p_{i,t,B}) =
\begin{cases}
(p_m,p_m) \ \ \text{if all elements of} \ \ H_{t-1} = (p_m,p_m), \text{or if} \ \ t=1 \cr
c \ \ \text{otherwise}
\end{cases} $$</p>

<p>The payoffs from cooperating and deviating are:</p>

<p>$$\begin{align}
\text{Cooperate:} &amp; \ \ (\frac{\pi_m}{N} + \frac{\pi_m}{N}) + (\delta\frac{\pi_m}{N} + \delta(1-\alpha)\frac{\pi_m}{N}) + (\delta^2\frac{\pi_m}{N} + \delta^2(1-\alpha)^2\frac{\pi_m}{N}) + ... \cr
&amp; = 2\frac{\pi_m}{N} + \frac{\pi_m}{N}\frac{\delta(1+(1-\alpha))}{1-\delta(1+(1-\alpha))} \cr \cr
\text{Deviate:} &amp; \ \ 2\pi_m + 0 + 0 + ... \cr
&amp; = 2\pi_m \cr
\end{align}$$</p>

<p>I&#39;m defining this as simply as I can: firms collude if other firms cooperate in both markets. Any firm who deviates is going to deviate in both markets at the same time. If firms see another firm deviate in either market, all firms go into the punishment phase and play \(p=c\) forever after. This way of defining it makes sense to me because deviating in both markets is better than deviating in one market, given the trigger strategy. I think this trigger strategy also prevents a firm from repeatedly defecting in only one market at a time, which could happen if a double-defection was needed to initiate the punishment phase.</p>

<p>Solving like before, we get</p>

<p>$$\delta_c \ge \frac{2(N-1)}{1+2(N-1)}\frac{1}{(2-\alpha)} $$</p>

<p>As \(N \to \infty\), \(\delta_c \to 1 ~~~ \forall \alpha\). When \(N=2\): </p>

<ul>
<li>\(\alpha\to0 \implies \delta_c \ge \frac{1}{3}\)</li>
<li>\(\alpha=\frac{1}{2} \implies \delta_c \ge 1\)</li>
<li>\(\alpha\to1 \implies \delta_c \ge \frac{2}{3}\)</li>
</ul>

<p>As I understand it, \(\alpha=\frac{1}{2}\) represents a state of total uncertainty - market B is equally likely to exist or not exist tomorrow. Any non-uniform distribution over the state of market B tomorrow gives the players more information about what is likely to happen than when \(\alpha=\frac{1}{2}\). When players are completely uncertain about whether or not market B will exist tomorrow, they need to weigh tomorrow at least as heavily as today in order to cooperate (given our assumptions on \(\delta\), they can&#39;t do that). When market B survives with probability 1, they are most likely to cooperate (\(\delta \ge \frac{1}{3}\)). When market B survives with probability 0, they need a discount factor of at least \(\frac{2}{3}\) to cooperate.</p>

<p>Collusion can be more or less likely in case 3 than case 2 or case 1. Depending on how likely it is that market B will exist tomorrow the firms&#39; payoffs from cooperating can be more than doubled, but their payoffs from deviating are doubled no matter what happens to market B tomorrow.</p>

<h3 id="summary">Summary</h3>

<p>The one-shot and finitely-repeated Bertrand games have very vicious competition, but as we see here the infinitely-repeated Bertrand game can support collusion if firms value the future highly enough. As the number of firms increases, collusion gets harder to support. When the market might end at any time, collusion gets harder to support. One way to make collusion more feasible when a market could end at any time is to have the firms compete simultaneously in another market that won&#39;t end. Depending on the probability of the second market ending, the two-market case may be more collusive than a single unending market. Repeated-play makes things interesting.</p>

<h4 id="variations-to-explore">Variations to explore</h4>

<ul>
<li><p>Infinitely-repeated Cournot oligopoly</p></li>
<li><p>Infinitely-repeated matrix game with correlated equilibria. The Folk Theorem can be used here.</p></li>
<li><p>Finitely-repeated and infinitely-repeated Rubinstein bargaining. Not really a variation of this - the only similarity is that they&#39;re both dynamic games - but still an interesting model.</p></li>
</ul>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>



<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
