<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      A Model A Day &middot; By Akhil Rao
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          A Model A Day
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/archive/">Archive</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/akhilrao/archive/v0.0.1.zip">Download</a>
      <a class="sidebar-nav-item" href="https://github.com/akhilrao">GitHub project</a>
      <span class="sidebar-nav-item">Currently v0.0.1</span>
    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/macro%20theory/2015/10/18/variable-capacity-utilization/">
        A representative agent's variable capacity utilization problem
      </a>
    </h1>

    <span class="post-date">18 Oct 2015</span>

    <p>Suppose a planner is solving a representative agent&#39;s problem. The agent can use capital at a varying rate \(\mu \in [0,1] \) and the depreciation rate \( \delta \) is affected by capital utilization, specifically \( \delta( \mu ) = \delta \mu^{\alpha} \) with \( 1 \lt \alpha \lt \infty \). The planner solves</p>

<p>$$ \begin{align}
\max_{\{c_t\},\{x_t\},\{k_{t+1}\},\{\mu_t\}} ~~ &amp; \sum_{t=0}^{\infty} \beta^t u(c_t) \cr
\text{s.t.}~~ &amp; c_t + x_t \le f( \mu_t k_t ) \cr
&amp; k_{t+1} \le (1-\delta(\mu_t))k_t + x_t \cr
&amp; c \ge 0,~ x_t \ge 0,~ k_{t+1} \ge 0,~ \mu_t \in [0,1] ~~ \forall t \cr
\end{align} $$</p>

<p>where \( \beta \in (0,1) \), \(k_0 \gt 0 \), and \( \delta \in (0,1) \). The utility function \(u\) and production function \(f\) are strictly concave, strictly increasing, and twice continuously differentiable, with \(f(0) = 0 \).</p>

<p>The planner&#39;s lagrangian is</p>

<p>$$\begin{align}
\mathcal{L} = &amp; u(c_t) + \lambda_{1,t}[f(\mu_t k_t) - c_t - x_t] + \lambda_{2,t}[(1-\delta\mu^{\alpha})k_t + x_t - k_{t+1}] \cr &amp; + \gamma_{1,t} c_t + \gamma_{2,t} x_t + \gamma_{3,t} k_{t+1} + \gamma_{4,t} \mu_t + \gamma_{5,t}(1- \mu_t) \cr 
\end{align}$$</p>

<h3 id="saddle-point-conditions">Saddle Point Conditions</h3>

<p>We can rule out 4 corners: \(c_t =0 ~~\forall t\),\(k_{t+1} =0 ~~\forall t\),\(x_t =0 ~~\forall t\),\(\mu_t =0 ~~\forall t\). The contradictions come from \(u\) being strictly concave and strictly increasing, so \(c_t\) can&#39;t be 0. Assuming the choice variables are all greater than 0, we get the following saddle point conditions:</p>

<p>$$ \begin{align}
u&#39;(c_t ) = &amp; \lambda_{1,t} \cr
\lambda_{1,t} = &amp; \lambda_{2,t} \cr
\lambda_{1,t} = &amp; \beta \lambda_{1,t+1} (\mu_{t+1} f^{k} (\mu_{t+1} k_{t+1}) + (1- \delta \mu^{\alpha})) \cr
\gamma_{5,t} = &amp; \lambda_{1,t} k_t (f^{\mu} (\mu_t k_t) - \delta \alpha \mu^{\alpha-1}) \cr
\end{align}$$</p>

<p>$$\begin{align}
\lambda_{1,t}(f(\mu_t k_t) - c_t - x_t) &amp; = 0 \cr
\lambda_{2,t}((1- \delta \mu^{\alpha})k_t + c_t - k_{t+1}) &amp; = 0 \cr
\gamma_{5,t} (1- \mu_t) &amp; = 0 \cr
\end{align} $$</p>

<p>where \( f^{\mu} (\mu k) \) and \( f^k (\mu k) \) are the partial derivatives of \( f \) with respect to the superscripted arguments. </p>

<p>Since this is an infinite-horizon problem, we need something to rule out an unbounded solution for the asset. One way to do this is with a <a href="http://www.rieb.kobe-u.ac.jp/academic/ra/dp/English/dp180.pdf">transversality condition (TVC)</a>. I think we need a TVC for each asset variable in the economy to rule out bubbles in those assets.</p>

<p>We can derive the TVC for capital as follows: 
Suppose \(T\) is the final period. Then \( \gamma_{3,T}k_{T+1} = 0\). In the final period, all \(T+1\) multipliers must be 0. So \( \gamma_{3,T} = \lambda_{1,T} \). Discounting back to \(t=0\), \( \beta^T \lambda_{1,T} K_{T+1} = 0 \), and in the limit, \( \lim_{T \to \infty} \beta^T \lambda_{1,T} K_{T+1} = 0 \). </p>

<p>Full capacity utilization may be optimal.</p>

<h3 id="the-steady-state">The Steady State</h3>

<p>The steady state is when the choice variables of the model are stationary. Here, \( c_t = c^*, k_t = k_{t+1} = k^* , x_t = x^*, \mu_t = \mu^* ~~ \forall t\).</p>

<p>In the steady state, the saddle point conditions become</p>

<p>$$ \begin{align}
&amp; \beta ( \mu^* f^k (\mu^* k^*) + (1-\delta \mu^{* \alpha})) = 1 \cr
&amp; \gamma_{5}^* = \lambda_{1}^* k^* (f^{\mu} (\mu^* k^*) - \delta \alpha \mu ^{* \alpha - 1}) \cr
&amp; \gamma_{5}^* (1- \mu^*) = 0 \cr
&amp; f(\mu^* k^*) = c^* + k^* \delta \mu^{* \alpha} \cr
\end{align}$$</p>

<p>The first condition there is the <a href="http://www.dictionaryofeconomics.com/article?id=pde2008_E000287">Euler-Ramsey Condition (ERC)</a> for this problem. </p>

<h3 id="existence-and-uniqueness">Existence and Uniqueness</h3>

<p>Under what conditions would the steady state exist and be unique? We can consider this in two cases: full capacity utilization and partial capacity utilization.</p>

<p><strong>Full capacity utilization</strong></p>

<p>In this case, \( \mu^* = 1 , \gamma_5^* \ge 0 \). From the ERC, we get that</p>

<p>$$ f^k ( k^*) = \beta^{-1} + \delta - 1 $$</p>

<p>If we assume that \( f^k ( k^*) \) is such that</p>

<p>$$\begin{align}
\lim_{k \to 0} \beta ( f^k ( k^*) - \delta + 1 ) \gt &amp; 1 \cr<br>
\lim_{k \to \infty} \beta ( f^k ( k^*) - \delta + 1 ) \lt &amp; 1 \cr<br>
\end{align}$$</p>

<p>then strict concavity and twice continuous differentiability of \( f \) guarantee existence and uniqueness of the steady state. I think this would be considered a corner solution of the model.</p>

<p>What is consumption in this case? The fourth steady state condition tells us that \( c^* = f(k^* ) - k^* \delta \), and the ERC tells us that \( f(k^* ) - \delta = \beta^{-1} - 1 \gt 0 \). So consumption is something strictly positive whenever it is optimal to utilize capacity fully.</p>

<p><strong>Partial capacity utilization</strong></p>

<p>In this case, \( \mu^* \lt 1 , \gamma_5^* = 0 \). This is a fully interior solution, and at the steady state \( f^{\mu} = f^k \) (equal marginal utility of inputs). From the ERC, we get that</p>

<p>$$ \mu^* = \left[ \left( \frac{1- \beta}{\beta} \right) \left( \frac{1}{\delta (\alpha - 1)} \right) \right]^{\frac{1}{\alpha}} $$</p>

<p>\( \mu^* \) exists as long as </p>

<p>$$ \left( \frac{1- \beta}{\beta} \right) \left( \frac{1}{\delta (\alpha - 1)} \right) \lt 1 $$</p>

<p>The second steady state condition pins down the marginal utility of capacity utilization through the depreciation rate. Formally, \( f^{\mu} ( \mu^* k^*) = \delta \alpha \mu^{* \alpha - 1} \). If we further assume</p>

<p>$$ \lim_{k \to 0} f^k ( \mu k ) = \infty $$</p>

<p>then we get that \( k^* \) exists \( \forall \mu \lt 1 \).</p>

<p>What is consumption in this case? The fourth steady state condition tells us that \( c^* = f( \mu^* k^* ) - k^* \delta \mu^{* \alpha} \). At the steady state, we know that \( f( \mu^* k^* ) \gt k^* \delta \mu^{* \alpha} \) - the optimal solution is such that the level of output is greater than the amount of depreciated utilized capital in each period. So consumption is also strictly positive when it is optimal to partially utilize capacity.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/15/principal-agent-problem-owner-manager/">
        A principal-agent problem between an owner and a manager
      </a>
    </h1>

    <span class="post-date">15 Oct 2015</span>

    <p>Suppose a firm&#39;s owner contracts a manager to run the firm. The firm&#39;s profit is a random variable \(\pi \in [\pi_a , \pi_b]\)  which the manager can influence through some effort. For simplicity, assume effort is discrete: \(e \in \{e_l,e_h\}\), with \(e_h \gt e_l \ge 0 \).  The manager&#39;s efforts are such that profits with \(e_h\) first-order stochastically dominate profits with \(e_l\), i.e. \(E \ [\pi|e_h] \gt E \ [\pi|e_l]\) and \( f(\pi|e) \gt 0 ~~ \forall \pi\). The manager&#39;s utility is \(u(w,e) = v(w) - g(e)\) with \(g(e_h) \gt g(e_l) \) and \(v&#39;(w) \gt 0, v&#39;&#39;(w) \lt 0\). The manager&#39;s utility strictly concave, so they are risk-averse. Let&#39;s assume the manager&#39;s reservation utility is \(\bar{u} \ge 0 \).</p>

<p>The idea is that the manager would prefer to exert less effort to more, but that more effort is likely to produce higher profits than less effort. No manager can control everything - profit is still a random variable and low realizations can occur when the manager exerts more effort, it&#39;s just less likely. The manager&#39;s reservaton utility is their outside offer or what they could produce at home. For clarity, let&#39;s call the owner she and the manager he.</p>

<h4 id="benchmark-case-effort-is-publicly-observable">Benchmark case: effort is publicly observable</h4>

<p>If the manager&#39;s efforts are publicly observable, then the owner solves</p>

<p>$$ \begin{align}
\max_{e \in \{e_l, e_h \}, w( \pi )} ~~&amp; \int_{\pi_a}^{\pi_b} [\pi - w( \pi )] f(\pi | e) ~ d \pi \cr
\text{s.t.} ~~&amp; \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \ge \bar{u}
\end{align} $$</p>

<p>We can think of this as a two-stage decision process: given some level of effort from the manager, the owner wants to pay him the profit-maximizing wage. The constraint is called an &quot;individual rationality (IR) constraint&quot; or a &quot;participation constraint&quot;. It&#39;s a way to factor the manager&#39;s problem into the owner&#39;s decision-making - the owner is constrained to pay the manager a wage that is at least as good as the manager&#39;s outside offer. If the owner doesn&#39;t, the manager won&#39;t work for her. For a fixed level of effort \(e\), the owner&#39;s problem can be simplified to minimizing the manager&#39;s wage subject to the participation constraint, or maximizing the negative of the manager&#39;s wage.</p>

<p>$$ \begin{align}
\min_{w( \pi )} ~~&amp; \int_{\pi_a}^{\pi_b} w( \pi ) f(\pi | e) ~ d \pi \cr
\text{s.t.} ~~&amp; \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \ge \bar{u}
\end{align} $$</p>

<p>A minimization problem can be made into a maximization problem by multiplying the objective by \(-1\). Economists seem to prefer maximization, while statisticians and computer scientists seem to prefer minimization. I&#39;m not sure why this is the case, or if it even is the case beyond my limited sample. </p>

<p>Since we integrated over \(\pi\) this wage holds for all realizations of profit. We can solve this as a constrained maximization</p>

<p>$$ \begin{align}
\mathcal{L} = &amp; - \int_{\pi_a}^{\pi_b} w( \pi ) f(\pi | e) ~ d \pi + \lambda [\int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) - \bar{u}] \cr
\text{FOC:} ~~ &amp; - \int_{\pi_a}^{\pi_b} f(\pi | e) ~ d \pi + \lambda \int_{\pi_a}^{\pi_b} v&#39;(w(\pi )) f(\pi | e) ~ d \pi = 0 \cr
\implies ~~ &amp; \frac{1}{v&#39;(w(\pi ))} = \lambda
\end{align} $$</p>

<p>From this we see that for a given level of effort, the optimal wage must be a constant. The optimal wage profile for any level of effort is to pay the manager the inverse wage-utility of the sum of their reservation utility and their marginal cost of effort, or \(w^*_e = v^{-1}(\bar{u} + g(e)) \). We can think of this as insurance against profit risk: the optimal contract will insure the risk-averse manager against any realization of profit, since the manager&#39;s effort doesn&#39;t guarantee high profits, just makes it more likely.</p>

<p>The lagrange multiplier \( \lambda\) on the participation constraint is the owner&#39;s <a href="https://en.wikipedia.org/wiki/Shadow_price">shadow price</a> of the manager&#39;s participation: it&#39;s the owner&#39;s (maximum) willingness-to-pay to marginally reduce the manager&#39;s reservation utility. More generally, the lagrange multiplier on a constraint is the improvement to the objective function from marginally relaxing that constraint.</p>

<p>The IR constraint must bind in this problem if the manager works for the owner. Any excess utility the owner gives the manager reduces the owner&#39;s profit, so the owner can always do better by reducing the manager&#39;s wage until the constraint binds.</p>

<h4 id="information-problem-effort-is-manager-39-s-private-information">Information problem: effort is manager&#39;s private information</h4>

<p>Now suppose the manager&#39;s effort level is not publicly observable anymore, it&#39;s the manager&#39;s private information. Now the owner solves</p>

<p>$$ \begin{align}
\min_{w( \pi )} ~~&amp; \int_{\pi_a}^{\pi_b} w( \pi ) f(\pi | e) ~ d \pi \cr
\text{s.t.} ~~&amp; \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \ge \bar{u} \cr
&amp; e = \text{argmax} ~~ \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e) ~ d \pi - g(e) \cr
\end{align} $$</p>

<p>The second constraint is called an &quot;incentive compatibility&quot; (IC) constraint. It says that the effort level the owner wants to implement has to be solve the manager&#39;s problem. I think of this as a refinement on the IR constraint - not only should it make sense for the manager to participate, it should be what they would most prefer to do. The manager should have no incentive to deviate. It&#39;s not quite the same as the IR constraint, since it&#39;s possible for the argmax of the manager&#39;s problem under effort is lower than the reservation utility.</p>

<p>Implementing \(e_l\) is easy - the owner just pays the manager the same wage as under observable effort. It satisfies the IR constraint, and at that wage the manager would put in low effort anyway (there is no profitable deviation). Implementing \(e_h\) is more interesting, since the IC constraint becomes important. For this problem, the IC implies</p>

<p>$$ \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e_h ) ~ d \pi - g(e_h ) \ge \int_{\pi_a}^{\pi_b} v(w(\pi )) f(\pi | e_l ) ~ d \pi - g(e_l ) $$</p>

<p>So the manager&#39;s expected value of putting in high effort has to be greater than or equal to his expected value of putting in low effort. If not, the manager has an incentive to deviate and since effort is unobservable, he will.</p>

<p>As before, we put it into a lagrangian. From the first-order condition of the owner&#39;s problem,</p>

<p>$$\begin{align}
w(\pi) : ~~ &amp; - \int_{\pi_a}^{\pi_b} f(\pi | e_h ) ~ d \pi + \lambda  \int_{\pi_a}^{\pi_b} v&#39;(w(\pi )) f(\pi | e_h ) ~ d\pi \cr + \ &amp; \gamma \int_{\pi_a}^{\pi_b} [f(\pi | e_h )-f(\pi | e_l )] \ v&#39;(w(\pi)) = 0 \cr
\implies ~~ &amp; \frac{1}{v&#39;(w(\pi ))} = \lambda + \gamma \left[ 1 - \frac{f(\pi|e_l )}{f(\pi|e_h )} \right]
\end{align}$$</p>

<p>The condition on the wage has the same component of the IR constraint multiplier - the shadow price of the manager&#39;s participation - and a new component from the IC constraint based on the shadow price of the manager&#39;s cooperation. This component is not a constant - it depends on the realizations of profit through the ratio of conditional densities of profit given effort. In repeated play, this term is a likelihood ratio. </p>

<p>By the same argument as earlier, the IR constraint must bind. By a similar argument, the IC constraint will also bind if high effort is implemented.</p>

<p>The cooperation shadow price is scaled based on the likelihood ratio of observed profits given effort, i.e. based on how likely the observed profits were given the efforts the manager could have exerted. I&#39;m not sure how to do this if effort were continuous; maybe a conditional expectation? </p>

<p>If the manager cooperates and doesn&#39;t shirk, the second component can be nearly as large as the owner&#39;s shadow price on cooperation (because the densities are strictly positive on the support, the likelihood ratio can be small but not 0). However, profits are random, and low realizations will affect the manager&#39;s pay - low realizations are just less likely when the manager is cooperating. I see the way the likelihood ratio enters as an &quot;information penalty&quot;. Without further restrictions, the penalty may cause the wage to be negative. I think this is unrealistic, but my guess is that adding a wage nonnegativity constraint will penalize the manager&#39;s wage, since the owner can&#39;t optimally punish the manager for bad profit realizations. I should try that.</p>

<p>My guess is that there is some connection between this information penalty and how much information is contained in the conditional distributions, or how sensitive profits are to efforts. I think that in the limiting case of the conditional distribution of profits being uniform for any effort level, the second term in the optimal wage would disappear. In that case, the owner would only pay the manager enough to participate, but since the owner has no information to check on the manager&#39;s effort levels, the owner won&#39;t pay the manager anything for exerting effort. In that case, I don&#39;t think an equilibrium where the manager exerts high effort can be sustained.</p>

<p>In the other direction, if the conditional distributions are highly informative about effort levels, then the penalties will be applied much more swiftly and harshly but also much less often if the manager is cooperating.</p>

<p>The information penalty also seems related to the <a href="https://en.wikipedia.org/wiki/Price_of_anarchy">Price of Anarchy</a>, like maybe a &quot;likelihood-PoA&quot; or something. I wonder if that&#39;s a thing.</p>

<p>It would be interesting to see a critical discount rate for the manager&#39;s cooperation in a dynamic version of this, given that he may be penalized even if he cooperates.</p>

<h4 id="conclusion">Conclusion</h4>

<p>This model is like my earlier attempt to model an owner-manager problem combined with the labor market signaling problem. Unlike the earlier problem, here the manager&#39;s behavior is embedded in the owner&#39;s problem as a constraint. This problem also abstracts away from the actual generation of profits - the owner in this problem only sees profits as a random variable, not as actual revenues and costs. This lets us get effort into the problem, which lets us drive a wedge between the owner and the manager. Given the manager&#39;s incentive compatibility constraint, it seems like low realizations of profits could cause the manager to shirk, but I&#39;m not sure if that&#39;s true.</p>

<p>The initial assumptions are somewhat strict, and it makes sense to change them based on the specific question at hand. One example I&#39;ve been thinking of is a mutual fund manager principal-agent problem. The owner would be the investor (the manager&#39;s client), the profits would be the mutual fund&#39;s returns, and effort would be trading activity. Many mutual funds charge commissions for &quot;active management&quot;, but generally portfolio returns are higher under &quot;passive management&quot;. This would require reversing our earlier assumptions about effort and the conditional distribution of profits given effort. In the benchmark case, we can imagine the investor is choosing between an actively managed fund versus a passively managed one. When the trading activity is hidden information, then there would probably be a condition very similar to the incentive compatibility constraint here that would scale the manager&#39;s pay based on observed portfolio returns, with a penalty for excess trading. </p>

<p>What if the principal doesn&#39;t know the conditional distribution of payoffs given the agent&#39;s actions? One way to model that could be as a Bayesian game - the principal has some beliefs over the distribution, and learns from repeated play.</p>

<p>I like this model a lot. The problems aren&#39;t hard to solve, but the way they go together makes the model do interesting things. The initial assumptions are important, but it is reasonable to change them and try things. I think these features make a model fun to play with. I wonder how well its predictions have held up if/when they&#39;ve been put to the data.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/12/eu-max-3-lottery/">
        An expected-utility maximizer and 3 lotteries
      </a>
    </h1>

    <span class="post-date">12 Oct 2015</span>

    <p>Consider an individual with preferences over lotteries that have an expected-utility representation. There are three lotteries this individual can choose from:</p>

<p>$$ L_1
\begin{cases}
\begin{align}
200 ~~~ &amp;P(200) = 1 \cr
\end{align}
\end{cases}$$</p>

<p>$$ L_2
\begin{cases}
\begin{align}
0 ~~~ &amp;P(0) = 2/3 \cr
200 ~~~ &amp;P(200) = 1/6 \cr
1000 ~~~ &amp;P(1000) = 1/6 \cr
\end{align}
\end{cases}$$</p>

<p>$$ L_3
\begin{cases}
\begin{align}
0 ~~~ &amp;P(0) = 1/3 \cr
400 ~~~ &amp;P(400) = 1/3 \cr
1000 ~~~ &amp;P(1000) = 1/3 \cr
\end{align}
\end{cases}$$</p>

<p>The expected utilities of the lotteries are:</p>

<p>$$\begin{align}
EU_{L1} =&amp; (200)(1) = 200 \cr
EU_{L2} =&amp; (0)(1/3) + (100)(1/6) + (1000)(1/6) \cr
 =&amp; 200 \cr
 EU_{L3} =&amp; (0)(1/3) + (100)(1/3) + (1000)(1/3) \cr
 =&amp; 1400/3 \cr
\end{align}$$</p>

<p>We can take a first pass at ordering the three lotteries by expected utility alone. This gives us that \( L_3 \succ L_2 \sim L_1\). To go further, we can use the concept of <a href="https://en.wikipedia.org/wiki/Stochastic_dominance">stochastic dominance</a>.</p>

<p>\(X \succ_{FSD} Y\) (X first-order stochastically dominates Y) if \(F_x (t) \le F_y (t) ~ \forall t \in [a,b]\), where \([a,b]\) is the support of \(F_x\) and \(F_y\). This is equivalent to saying \(X \succ_{FSD} Y\) iff \( E[u(x)] \ge E[u(y)] ~ \forall\) nondecreasing, continuous functions \(u\). We apply this concept when we order the lotteries by expected utility.</p>

<p>Second-order stochastic dominance is a refinement on this. We say \(X \succ_{SSD} Y\) (X second-order stochastically dominates Y) if \(\int_a^w F_x (t) dt \le \int_a^w F_y (t) dt ~ \forall w \in [a,b]\), where \([a,b]\) is the support of \(F_x\) and \(F_y\). This is equivalent to saying \(X \succ_{SSD} Y\) iff \( E[u(x)] \ge E[u(y)] ~ \forall\) nondecreasing, continuous, and <em>concave</em> functions \(u\). We apply this concept when we order the lotteries by expected utility.</p>

<p>If all we have is that the agent is an expected-utility maximizer then all we can do is apply first-order stochastic dominance and say that the agent will prefer \(L_3\) over \(L_1\) and \(L_2\), and be indifferent between \(L_1\) and \(L_2\).</p>

<p>If we know or are willing to assume that the agent is risk-averse - that their utility function \(u\) is concave - then we can apply second-order stochastic dominance and rank the lotteries \(L_3 \succ L_1 \succ L_2 \). The risk-averse agent would rather take the safe 200-for-sure than the risky 200-on-average.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/11/monopoly-pricing-discrete-sequential-demand/">
        Monopoly pricing for sequential discrete demand
      </a>
    </h1>

    <span class="post-date">11 Oct 2015</span>

    <p>Today&#39;s post is a variation on <a href="http://akhilrao.github.io/micro%20theory/2015/10/04/monopoly-pricing-discrete-demand/">monopoly pricing for discrete demand</a>.</p>

<p>Suppose you&#39;re moving, and you have a piece of used furniture that you need to sell. You&#39;ve got two potential buyers, \(B_1\) and \(B_2\), lined up to buy it. They arrive sequentially, so \(B_2\) won&#39;t have anything to look at if \(B_1\) buys. Assume \(B_i\) is willing to pay \(v_i\) for the furniture, where \(v_i\) is an independent draw from a uniform CDF \(F(v_i) = \frac{v_i - a}{b - a}\) for \(v_i \in [a,b]\). The furniture has no value to you if it isn&#39;t sold - you can&#39;t take it with you - and there is no discounting. There&#39;s no bargaining, either - you get to make a take-it-or-leave-it offer to each buyer.</p>

<p>Let&#39;s start at the end of this game with some numbers: \(a=40, b=140\).</p>

<h4 id="pricing-for-the-second-buyer">Pricing for the second buyer</h4>

<p>Suppose \(B_1\) rejected your offer, so you&#39;re pricing it for \(B_2\). The game ends if this buyer rejects, so this round is basically a standard discrete demand monopoly pricing problem. Your price solves</p>

<p>$$ \max_{p_2} ~ (p_2-c)(1-F(p_2)) $$</p>

<p>Giving us</p>

<p>$$ p_2 = c + \frac{1-F(p_2 )}{f(p_2 )} $$</p>

<p>In this example, the marginal cost would be the opportunity cost - the value of the furniture to you if you didn&#39;t sell it. We know that&#39;s 0 here because you&#39;re moving and can&#39;t take it with you. Plugging in for this uniform CDF and PDF, the optimal price becomes</p>

<p>$$\begin{align}
 p_2 &amp;= \frac{b}{2} \cr
\implies p_2 &amp;= 70 \cr
\end{align} $$</p>

<p>Your expected profits from this pricing scheme are</p>

<p>$$\begin{align}
\pi_2 &amp;= (p_2-c)(1-F(p_2)) \cr
&amp;= (70)(\frac{70}{100}) \cr
&amp;= 49 \cr 
\end{align}$$</p>

<p>Note that there&#39;s no discounting here - if there was, we&#39;d be hitting this expected profit with a discount rate, and it would be lower than 49.</p>

<h4 id="pricing-for-the-first-buyer">Pricing for the first buyer</h4>

<p>Now that we know the end of the game, we can go backwards to the first round. You&#39;re solving the same problem for the first buyer, but now you have to keep in mind that if the first person doesn&#39;t buy, you&#39;ve still got the second person coming. The optimal price will solve</p>

<p>$$ \max_{p_1} ~ p_1(1-F(p_1)) + F(p_1) \pi_2 $$</p>

<p>Giving us</p>

<p>$$ p_1 = \frac{189}{2} \gt p_2 $$</p>

<p>This is nice and what we would expect: when you have multiple buyers lined up, your price should decrease over time as buyers reject, if only because there are fewer buyers coming later. The last buyer should receive the lowest price.</p>

<p>To round it off, your expected profits in the first stage would be 73.7975. Your expected profits decrease as you move through the buyers, since your price gets lower and you lose the expected value of the future buyers.</p>

<p>Adding discounting wouldn&#39;t change the key features of this problem. Adding bargaining would, since the buyers wouldn&#39;t have to accept your profit-maximizing price. Discounting plus bargaining would change things by giving the person with the higher discount rate (more patience) an advantage. This is what happens in Rubinstein bargaining games.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/macro%20theory/2015/10/10/otj-search/">
        On-the-job search with dynamic programming
      </a>
    </h1>

    <span class="post-date">10 Oct 2015</span>

    <p>Consider a worker trying to maximize lifetime consumption and leisure. She needs a job to get stuff to consume, which eats into her leisure time, and gives us an interesting tradeoff to study.</p>

<p>The total time available is normalized to 1 and everything is measured in terms of the consumption good. For any wage \(w_t\), the worker needs to decide how much time to work, \(1-l_t\). Her labor income is \(w_t (1-l_t)\). If she&#39;s unemployed, she gets to spend all her time on leisure, but she gets no income and therefore no consumption. Formally, the worker solves</p>

<p>$$\begin{align}
\max_{c_t,l_t} &amp;~ E_0 \sum_{t=0}^{\infty} \beta^t[\ln c_t + \phi \ln l_t] \cr
\text{s.t.} &amp;~ 0 \le l \le 1 \cr
&amp;~ c_t \le w_t (1-l_t)
\end{align}$$</p>

<p>where \(\beta \in (0,1)\) and \(\phi \gt 0\).</p>

<p>In the beginning of each period, the unemployed worker receives an offer \(w \in [0,B],~B \lt \infty\), drawn randomly from the continuous distribution function \(F(w)\). If the worker accepts the offer, she begins receiving labor income in the same period.</p>

<p>The employed worker can pay a search cost \(z \gt 0\) to receive another offer randomly drawn from the same distribution, \(F(w)\) - she can keep searching on the job. If she accepts the offer, she begins working at the new job in the following period.</p>

<p>To keep things simple, let&#39;s assume there is no exogenous job destruction; once an offer is accepted, the job survives with probability 1. There is no saving or borrowing.</p>

<p>The utility function is natural log in consumption and leisure, so we can rule out 0 and \(\infty\) as solutions. The unemployed worker will always accept their first job offer. The action is in the employed worker searching.</p>

<h4 id="the-bellman-equations">The Bellman equations</h4>

<p>To solve this problem, we break the consumer&#39;s decision over infinite periods down into a series of smaller one-period decisions and find an optimal solution to that one equation (<a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a>). In each period, the workers face the following decisions:</p>

<p>$$\begin{align}
\text{Unemployed:} ~~ V^u (w) &amp; = \max_l \{accept , ~ reject \} \cr
&amp; = \max_l \{ u(w(1-l),l) + \beta V^e (w), u(0,1)\} \cr
\end{align}$$</p>

<p>Clearly, the unemployed will always accept any offer \(w \gt 0\).</p>

<p>$$\begin{align}
\text{Employed:} ~~ V^e (w) &amp; = \max_l \{don&#39;t~search , ~ search \} \cr
&amp; = \max_l \left\{ \frac{u(w(1-l),l)}{1-\beta}, \frac{u(w(1-l)-z,l)}{1-\beta} + \frac{\beta}{1-\beta} \int_w^B (V^e (w&#39;) - V^e (w)) \ dF(w&#39;) \right\} \cr
\end{align}$$</p>

<p>\(w&#39;\) is the next period&#39;s offer. The search integral is a <a href="https://en.wikipedia.org/wiki/Lebesgue_integration">Lebesgue integral</a> over the wage distribution. The worker will obviously not accept an offer at a wage lower than the current one, so we only integrate over the current wage to the upper bound.</p>

<h4 id="is-there-a-reservation-wage">Is there a reservation wage?</h4>

<p>In this context, &quot;is there a wage \(\bar{w}\) such that the employed worker searches if and only if \(w \le \bar{w}\)&quot;? The answer is yes. To find \(\bar{w}\), let&#39;s assume it exists, in which case it satisfies </p>

<p>$$V^e (Don&#39;t~search) = V^e (Search)$$ </p>

<p>Then we do some algebra and get that</p>

<p>$$\bar{w}:~ \ln(w(1-l)) - \ln(w(1-l)-z) = \beta \int_{\bar{w}}^B (V^e (w&#39;) - V^e (\bar{w})) \ dF(w&#39;) $$</p>

<p>The LHS is the search penalty to the marginal utility of consumption (marginal cost of searching), and the RHS is the discounted expected increase in wage from the search (marginal benefit of searching).</p>

<p>What else can we say about the worker&#39;s search behavior?</p>

<ul>
<li><p>As \(w \to 0 \), \(V^e_s (w) \to -\infty\) faster than \(V^e_n (w) \to -\infty\). So at a low enough wage, the search cost \(z\) has a large effect on the worker&#39;s utility and she won&#39;t search.</p></li>
<li><p>At \(w=B\),
$$\begin{align}
V^e_s (B) &amp; = (1-\beta)^{-1} (\ln(B(1-l)-z) + \phi \ \ln(l)) \cr
V^e_n (B) &amp; = (1-\beta)^{-1} (\ln(B(1-l)) + \phi \ \ln(l)) \cr
\implies V^e_n (B) &amp; \gt V^e_s (B)
\end{align}$$
So the worker won&#39;t search when she&#39;s already earning the maximum wage, which is pretty intuitive.</p></li>
</ul>

<p>So the worker won&#39;t search at a low enough wage, and she won&#39;t search at the highest wage... since the value of searching and not searching are both concave functions, this means they must touch twice if they cross. They could potentially touch only once if they don&#39;t cross. This makes things complicated, since now there are potentially three wages where the condition we used to find the reservation wage holds: in the case where they cross, there&#39;s the wage at which workers start searching and the wage at which the workers stop searching (what we found); in the case where they touch only once, there&#39;s the wage at which workers are indifferent between searching and not searching.  </p>

<p>To make life easier, let&#39;s assume \(z\) is small enough that \(V^e_s (w) \lt V^e_n (w)\) occurs on the lower end of the wage scale only at wages below 1 (so negative utilities), and the only place where our reservation wage condition holds that matters is the one we explored. Utility has a cardinal interpretation here, so we can rule out the case of the worker earning so little she can&#39;t afford to search. </p>

<p>Anyway, with this behavior, in the long run we should expect every worker to end up with a wage above their reservation wage, since they&#39;ll keep searching for a better job otherwise.</p>

<p>In a future post, I&#39;ll relax the assumption that \(z\) is very small and sketch out all the cases of the reservation wage, and explore the worker&#39;s labor supply behavior in this model.</p>

<p>Dynamic programming is a powerful way to get a simple solution to an optimization problem. Without it, we would have had to set up and solve an infinite-period optimization. With it, we can just find a consistent decision rule for an arbitrary period. To use DP, we need some assumptions on the functions we&#39;re optimizing. When I revisit this model, maybe I&#39;ll talk about those assumptions as well.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>



<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
