<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      A Model A Day &middot; By Akhil Rao
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body>

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          A Model A Day
        </a>
      </h1>
      <p class="lead"></p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item active" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/archive/">Archive</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/akhilrao/archive/v0.0.1.zip">Download</a>
      <a class="sidebar-nav-item" href="https://github.com/akhilrao">GitHub project</a>
      <span class="sidebar-nav-item">Currently v0.0.1</span>
    </nav>

    <p>&copy; 2015. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/13/2015-14-04-principal-agent-problem-owner-manager/">
        An principal-agent problem between an owner and a manager
      </a>
    </h1>

    <span class="post-date">13 Oct 2015</span>

    <p>Suppose a firm is run by a manager, contracted by the owner. The firm&#39;s profit is a random variable \(\pi \in [\pi_a , \pi_b]\)  which the manager can influence through some effort. For simplicity, assume effort is discrete: \(e \in \{e_l,e_h\}\), with \(e_h \gt e_l \ge 0 \).  The manager&#39;s efforts are such that profits with \(e_h\) first-order stochastically dominate profits with \(e_l\), i.e. \(E \ [\pi|e_h] \gt E \ [\pi|e_l]\) and \( f(\pi|e) \gt 0 ~~ \forall \pi\). The manager&#39;s utility is \(u(w,e) = v(w) - g(e)\) with \(g(e_h) \gt g(e_l) \) and \(v&#39;(w) \gt 0, v&#39;&#39;(w) \lt 0\). The manager&#39;s utility strictly concave, so they are risk-averse. Let&#39;s assume the manager&#39;s reservation utility is \(\bar{u} \ge 0 \).</p>

<p>The idea is that the manager would prefer to exert less effort to more, but that more effort is likely to produce higher profits than less effort. No manager can control everything - profit is still a random variable and low realizations can occur when the manager exerts more effort, it&#39;s just less likely. The manager&#39;s reservaton utility is their outside offer or what they could produce at home. For clarity, let&#39;s call the owner she and the manager he.</p>

<h4 id="benchmark-case-effort-is-publicly-observable">Benchmark case: effort is publicly observable</h4>

<p>If the manager&#39;s efforts are publicly observable, then the owner solves</p>

<p>MATH</p>

<p>We can think of this as a two-stage decision process: given some level of effort from the manager, the owner wants to pay him the profit-maximizing wage. The constraint is called an &quot;individual rationality (IR) constraint&quot; or a &quot;participation constraint&quot;, which is basically a way to embed the manager&#39;s problem into the owner&#39;s decision-making. The owner is constrained to pay the manager a wage that is at least as good as the manager&#39;s outside offer. If the owner doesn&#39;t, the manager won&#39;t work for her.</p>

<p>MATH</p>

<p>Since we integrated over \(\pi\) this wage holds for all realizations of profit. The optimal wage profile for any level of effort is to pay the manager the inverse wage-utility of the sum of their reservation utility and their marginal cost of effort, or \(w^*_e = v^{-1}(\bar{u} + g(e)) \). From this we see that for a given level of effort, the optimal wage must be a constant. We can think of this as insurance against profit risk: the optimal contract will insure the risk-averse manager against any realization of profit, since the manager&#39;s effort doesn&#39;t guarantee high profits, just makes it more likely.</p>

<p>The lagrange multiplier on the constraint is the owner&#39;s shadow price of the manager&#39;s participation: it&#39;s what the owner would give to marginally reduce the manager&#39;s reservation utility.</p>

<h4 id="information-problem-effort-is-manager-39-s-private-information">Information problem: effort is manager&#39;s private information</h4>

<p>ASSUMPTIONS, MOTIVATION</p>

<p>INCENTIVE COMPATIBILITY CONSTRAINT</p>

<p>MATH</p>

<p>SHADOW PRICES</p>

<p>When the manager&#39;s effort is private information, the profit maximizing wage is no longer a constant, it depends on the likelihoods of profits under the different effort levels. From the first-order condition, we can see that the optimal wage profile has a component based on the shadow price of the manager&#39;s participation, and a component based on the shadow price of the manager&#39;s cooperation. The latter term is scaled based on the likelihood ratio of profits given effort, i.e. based on how likely the observed profits were given the efforts the manager may have exerted. If the manager cooperates and doesn&#39;t shirk, this component can be nearly as large as the owner&#39;s shadow price on cooperation. However, profits are random, and low realizations will affect the manager&#39;s pay - low realizations are just less likely when the manager is cooperating. It would be interesting to see a critical discount rate for the manager&#39;s cooperating in a dynamic version of this.</p>

<h4 id="summary">Summary</h4>

<p>This model seems like my earlier attempt to model an owner-manager problem combined with the labor market signaling problem. Unlike the earlier problem, here the manager&#39;s behavior is embedded in the owner&#39;s problem as a constraint. This problem also abstracts away from the actual generation of profits - the owner in this problem only sees profits as a random variable, not as actual revenues and costs. This lets us get effort into the problem, which lets us drive a wedge between the owner and the manager. Given the manager&#39;s incentive compatibility constraint, it seems like low realizations of profits could cause the manager to shirk, but I&#39;m not sure if that&#39;s true.</p>

<p>The initial assumptions are somewhat strict, and it makes sense to change them based on the specific question at hand. One example I&#39;ve been thinking of is a mutual fund manager principal-agent problem. The owner would be the investor (the manager&#39;s client), the profits would be the mutual fund&#39;s returns, and effort would be trading activity. Many mutual funds charge commissions for &quot;active management&quot;, but generally portfolio returns are higher under &quot;passive management&quot;. In the benchmark case, we can imagine the investor is choosing between an actively managed fund versus a passively managed one. When the trading activity is hidden information, then there would probably be a condition very similar to the incentive compatibility constraint here that would scale the manager&#39;s pay based on observed portfolio returns.</p>

<p>What if the principal doesn&#39;t know the conditional distribution of payoffs given the agent&#39;s actions? One way to model that could be as a Bayesian game - the principal has some beliefs over the distribution, and learns from repeated play.</p>

<p>I like this model a lot. The problems aren&#39;t hard to solve, but the way they go together makes the model do interesting things. The initial assumptions are important, but it is reasonable to change them and try things. I think these features make a model fun to play with. I wonder how well its predictions have held up if/when they&#39;ve been put to the data.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/12/eu-max-3-lottery/">
        An expected-utility maximizer and 3 lotteries
      </a>
    </h1>

    <span class="post-date">12 Oct 2015</span>

    <p>Consider an individual with preferences over lotteries that have an expected-utility representation. There are three lotteries this individual can choose from:</p>

<p>$$ L_1
\begin{cases}
\begin{align}
200 ~~~ &amp;P(200) = 1 \cr
\end{align}
\end{cases}$$</p>

<p>$$ L_2
\begin{cases}
\begin{align}
0 ~~~ &amp;P(0) = 2/3 \cr
200 ~~~ &amp;P(200) = 1/6 \cr
1000 ~~~ &amp;P(1000) = 1/6 \cr
\end{align}
\end{cases}$$</p>

<p>$$ L_3
\begin{cases}
\begin{align}
0 ~~~ &amp;P(0) = 1/3 \cr
400 ~~~ &amp;P(400) = 1/3 \cr
1000 ~~~ &amp;P(1000) = 1/3 \cr
\end{align}
\end{cases}$$</p>

<p>The expected utilities of the lotteries are:</p>

<p>$$\begin{align}
EU_{L1} =&amp; (200)(1) = 200 \cr
EU_{L2} =&amp; (0)(1/3) + (100)(1/6) + (1000)(1/6) \cr
 =&amp; 200 \cr
 EU_{L3} =&amp; (0)(1/3) + (100)(1/3) + (1000)(1/3) \cr
 =&amp; 1400/3 \cr
\end{align}$$</p>

<p>We can take a first pass at ordering the three lotteries by expected utility alone. This gives us that \( L_3 \succ L_2 \sim L_1\). To go further, we can use the concept of <a href="https://en.wikipedia.org/wiki/Stochastic_dominance">stochastic dominance</a>.</p>

<p>\(X \succ_{FSD} Y\) (X first-order stochastically dominates Y) if \(F_x (t) \le F_y (t) ~ \forall t \in [a,b]\), where \([a,b]\) is the support of \(F_x\) and \(F_y\). This is equivalent to saying \(X \succ_{FSD} Y\) iff \( E[u(x)] \ge E[u(y)] ~ \forall\) nondecreasing, continuous functions \(u\). We apply this concept when we order the lotteries by expected utility.</p>

<p>Second-order stochastic dominance is a refinement on this. We say \(X \succ_{SSD} Y\) (X second-order stochastically dominates Y) if \(\int_a^w F_x (t) dt \le \int_a^w F_y (t) dt ~ \forall w \in [a,b]\), where \([a,b]\) is the support of \(F_x\) and \(F_y\). This is equivalent to saying \(X \succ_{SSD} Y\) iff \( E[u(x)] \ge E[u(y)] ~ \forall\) nondecreasing, continuous, and <em>concave</em> functions \(u\). We apply this concept when we order the lotteries by expected utility.</p>

<p>If all we have is that the agent is an expected-utility maximizer then all we can do is apply first-order stochastic dominance and say that the agent will prefer \(L_3\) over \(L_1\) and \(L_2\), and be indifferent between \(L_1\) and \(L_2\).</p>

<p>If we know or are willing to assume that the agent is risk-averse - that their utility function \(u\) is concave - then we can apply second-order stochastic dominance and rank the lotteries \(L_3 \succ L_1 \succ L_2 \). The risk-averse agent would rather take the safe 200-for-sure than the risky 200-on-average.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/micro%20theory/2015/10/11/monopoly-pricing-discrete-sequential-demand/">
        Monopoly pricing for sequential discrete demand
      </a>
    </h1>

    <span class="post-date">11 Oct 2015</span>

    <p>Today&#39;s post is a variation on <a href="http://akhilrao.github.io/micro%20theory/2015/10/04/monopoly-pricing-discrete-demand/">monopoly pricing for discrete demand</a>.</p>

<p>Suppose you&#39;re moving, and you have a piece of used furniture that you need to sell. You&#39;ve got two potential buyers, \(B_1\) and \(B_2\), lined up to buy it. They arrive sequentially, so \(B_2\) won&#39;t have anything to look at if \(B_1\) buys. Assume \(B_i\) is willing to pay \(v_i\) for the furniture, where \(v_i\) is an independent draw from a uniform CDF \(F(v_i) = \frac{v_i - a}{b - a}\) for \(v_i \in [a,b]\). The furniture has no value to you if it isn&#39;t sold - you can&#39;t take it with you - and there is no discounting. There&#39;s no bargaining, either - you get to make a take-it-or-leave-it offer to each buyer.</p>

<p>Let&#39;s start at the end of this game with some numbers: \(a=40, b=140\).</p>

<h4 id="pricing-for-the-second-buyer">Pricing for the second buyer</h4>

<p>Suppose \(B_1\) rejected your offer, so you&#39;re pricing it for \(B_2\). The game ends if this buyer rejects, so this round is basically a standard discrete demand monopoly pricing problem. Your price solves</p>

<p>$$ \max_{p_2} ~ (p_2-c)(1-F(p_2)) $$</p>

<p>Giving us</p>

<p>$$ p_2 = c + \frac{1-F(p_2 )}{f(p_2 )} $$</p>

<p>In this example, the marginal cost would be the opportunity cost - the value of the furniture to you if you didn&#39;t sell it. We know that&#39;s 0 here because you&#39;re moving and can&#39;t take it with you. Plugging in for this uniform CDF and PDF, the optimal price becomes</p>

<p>$$\begin{align}
 p_2 &amp;= \frac{b}{2} \cr
\implies p_2 &amp;= 70 \cr
\end{align} $$</p>

<p>Your expected profits from this pricing scheme are</p>

<p>$$\begin{align}
\pi_2 &amp;= (p_2-c)(1-F(p_2)) \cr
&amp;= (70)(\frac{70}{100}) \cr
&amp;= 49 \cr 
\end{align}$$</p>

<p>Note that there&#39;s no discounting here - if there was, we&#39;d be hitting this expected profit with a discount rate, and it would be lower than 49.</p>

<h4 id="pricing-for-the-first-buyer">Pricing for the first buyer</h4>

<p>Now that we know the end of the game, we can go backwards to the first round. You&#39;re solving the same problem for the first buyer, but now you have to keep in mind that if the first person doesn&#39;t buy, you&#39;ve still got the second person coming. The optimal price will solve</p>

<p>$$ \max_{p_1} ~ p_1(1-F(p_1)) + F(p_1) \pi_2 $$</p>

<p>Giving us</p>

<p>$$ p_1 = \frac{189}{2} \gt p_2 $$</p>

<p>This is nice and what we would expect: when you have multiple buyers lined up, your price should decrease over time as buyers reject, if only because there are fewer buyers coming later. The last buyer should receive the lowest price.</p>

<p>To round it off, your expected profits in the first stage would be 73.7975. Your expected profits decrease as you move through the buyers, since your price gets lower and you lose the expected value of the future buyers.</p>

<p>Adding discounting wouldn&#39;t change the key features of this problem. Adding bargaining would, since the buyers wouldn&#39;t have to accept your profit-maximizing price. Discounting plus bargaining would change things by giving the person with the higher discount rate (more patience) an advantage. This is what happens in Rubinstein bargaining games.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/macro%20theory/2015/10/10/otj-search/">
        On-the-job search with dynamic programming
      </a>
    </h1>

    <span class="post-date">10 Oct 2015</span>

    <p>Consider a worker trying to maximize lifetime consumption and leisure. She needs a job to get stuff to consume, which eats into her leisure time, and gives us an interesting tradeoff to study.</p>

<p>The total time available is normalized to 1 and everything is measured in terms of the consumption good. For any wage \(w_t\), the worker needs to decide how much time to work, \(1-l_t\). Her labor income is \(w_t (1-l_t)\). If she&#39;s unemployed, she gets to spend all her time on leisure, but she gets no income and therefore no consumption. Formally, the worker solves</p>

<p>$$\begin{align}
\max_{c_t,l_t} &amp;~ E_0 \sum_{t=0}^{\infty} \beta^t[\ln c_t + \phi \ln l_t] \cr
\text{s.t.} &amp;~ 0 \le l \le 1 \cr
&amp;~ c_t \le w_t (1-l_t)
\end{align}$$</p>

<p>where \(\beta \in (0,1)\) and \(\phi \gt 0\).</p>

<p>In the beginning of each period, the unemployed worker receives an offer \(w \in [0,B],~B \lt \infty\), drawn randomly from the continuous distribution function \(F(w)\). If the worker accepts the offer, she begins receiving labor income in the same period.</p>

<p>The employed worker can pay a search cost \(z \gt 0\) to receive another offer randomly drawn from the same distribution, \(F(w)\) - she can keep searching on the job. If she accepts the offer, she begins working at the new job in the following period.</p>

<p>To keep things simple, let&#39;s assume there is no exogenous job destruction; once an offer is accepted, the job survives with probability 1. There is no saving or borrowing.</p>

<p>The utility function is natural log in consumption and leisure, so we can rule out 0 and \(\infty\) as solutions. The unemployed worker will always accept their first job offer. The action is in the employed worker searching.</p>

<h4 id="the-bellman-equations">The Bellman equations</h4>

<p>To solve this problem, we break the consumer&#39;s decision over infinite periods down into a series of smaller one-period decisions and find an optimal solution to that one equation (<a href="https://en.wikipedia.org/wiki/Dynamic_programming">dynamic programming</a>). In each period, the workers face the following decisions:</p>

<p>$$\begin{align}
\text{Unemployed:} ~~ V^u (w) &amp; = \max_l \{accept , ~ reject \} \cr
&amp; = \max_l \{ u(w(1-l),l) + \beta V^e (w), u(0,1)\} \cr
\end{align}$$</p>

<p>Clearly, the unemployed will always accept any offer \(w \gt 0\).</p>

<p>$$\begin{align}
\text{Employed:} ~~ V^e (w) &amp; = \max_l \{don&#39;t~search , ~ search \} \cr
&amp; = \max_l \left\{ \frac{u(w(1-l),l)}{1-\beta}, \frac{u(w(1-l)-z,l)}{1-\beta} + \frac{\beta}{1-\beta} \int_w^B (V^e (w&#39;) - V^e (w)) \ dF(w&#39;) \right\} \cr
\end{align}$$</p>

<p>\(w&#39;\) is the next period&#39;s offer. The search integral is a <a href="https://en.wikipedia.org/wiki/Lebesgue_integration">Lebesgue integral</a> over the wage distribution. The worker will obviously not accept an offer at a wage lower than the current one, so we only integrate over the current wage to the upper bound.</p>

<h4 id="is-there-a-reservation-wage">Is there a reservation wage?</h4>

<p>In this context, &quot;is there a wage \(\bar{w}\) such that the employed worker searches if and only if \(w \le \bar{w}\)&quot;? The answer is yes. To find \(\bar{w}\), let&#39;s assume it exists, in which case it satisfies </p>

<p>$$V^e (Don&#39;t~search) = V^e (Search)$$ </p>

<p>Then we do some algebra and get that</p>

<p>$$\bar{w}:~ \ln(w(1-l)) - \ln(w(1-l)-z) = \beta \int_{\bar{w}}^B (V^e (w&#39;) - V^e (\bar{w})) \ dF(w&#39;) $$</p>

<p>The LHS is the search penalty to the marginal utility of consumption (marginal cost of searching), and the RHS is the discounted expected increase in wage from the search (marginal benefit of searching).</p>

<p>What else can we say about the worker&#39;s search behavior?</p>

<ul>
<li><p>As \(w \to 0 \), \(V^e_s (w) \to -\infty\) faster than \(V^e_n (w) \to -\infty\). So at a low enough wage, the search cost \(z\) has a large effect on the worker&#39;s utility and she won&#39;t search.</p></li>
<li><p>At \(w=B\),
$$\begin{align}
V^e_s (B) &amp; = (1-\beta)^{-1} (\ln(B(1-l)-z) + \phi \ \ln(l)) \cr
V^e_n (B) &amp; = (1-\beta)^{-1} (\ln(B(1-l)) + \phi \ \ln(l)) \cr
\implies V^e_n (B) &amp; \gt V^e_s (B)
\end{align}$$
So the worker won&#39;t search when she&#39;s already earning the maximum wage, which is pretty intuitive.</p></li>
</ul>

<p>So the worker won&#39;t search at a low enough wage, and she won&#39;t search at the highest wage... since the value of searching and not searching are both concave functions, this means they must touch twice if they cross. They could potentially touch only once if they don&#39;t cross. This makes things complicated, since now there are potentially three wages where the condition we used to find the reservation wage holds: in the case where they cross, there&#39;s the wage at which workers start searching and the wage at which the workers stop searching (what we found); in the case where they touch only once, there&#39;s the wage at which workers are indifferent between searching and not searching.  </p>

<p>To make life easier, let&#39;s assume \(z\) is small enough that \(V^e_s (w) \lt V^e_n (w)\) occurs on the lower end of the wage scale only at wages below 1 (so negative utilities), and the only place where our reservation wage condition holds that matters is the one we explored. Utility has a cardinal interpretation here, so we can rule out the case of the worker earning so little she can&#39;t afford to search. </p>

<p>Anyway, with this behavior, in the long run we should expect every worker to end up with a wage above their reservation wage, since they&#39;ll keep searching for a better job otherwise.</p>

<p>In a future post, I&#39;ll relax the assumption that \(z\) is very small and sketch out all the cases of the reservation wage, and explore the worker&#39;s labor supply behavior in this model.</p>

<p>Dynamic programming is a powerful way to get a simple solution to an optimization problem. Without it, we would have had to set up and solve an infinite-period optimization. With it, we can just find a consistent decision rule for an arbitrary period. To use DP, we need some assumptions on the functions we&#39;re optimizing. When I revisit this model, maybe I&#39;ll talk about those assumptions as well.</p>

  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/2015/10/09/no-post-today/">
        No post today
      </a>
    </h1>

    <span class="post-date">09 Oct 2015</span>

    <p>No model today.</p>

<p>Tomorrow: a labor search problem.</p>

  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>
    </div>

  </body>
</html>



<script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
